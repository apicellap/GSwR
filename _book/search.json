[{"path":"index.html","id":"about","chapter":"About","heading":"About","text":"resource encompasses compiled notes , Getting Started R: Introduction Biologists Second edition. notes meant replace textbook. Instead may act helpful guide.","code":""},{"path":"getting-acqainted-with-r.html","id":"getting-acqainted-with-r","chapter":"1 Getting Acqainted with R","heading":"1 Getting Acqainted with R","text":"","code":""},{"path":"getting-acqainted-with-r.html","id":"using-r-as-a-giant-calculator","chapter":"1 Getting Acqainted with R","heading":"1.1 Using R as a giant calculator","text":"Produce sequence numbers:","code":"\nseq(from = 0,\n    to = 10, \n    by = 1) #interval ##  [1]  0  1  2  3  4  5  6  7  8  9 10"},{"path":"getting-acqainted-with-r.html","id":"your-first-script","chapter":"1 Getting Acqainted with R","heading":"1.2 Your first script","text":"Creating objects:Add objects together create new object:Print session information:","code":"\nx<-seq(from = 0, to = 10, by =0.5)\nx##  [1]  0.0  0.5  1.0  1.5  2.0  2.5  3.0  3.5  4.0  4.5  5.0  5.5  6.0  6.5  7.0\n## [16]  7.5  8.0  8.5  9.0  9.5 10.0\ny<-seq(from = 101, to = 110, by =0.5)\nz <- x + y  ## Warning in x + y: longer object length is not a multiple of shorter object\n## length\nz##  [1] 101.0 102.0 103.0 104.0 105.0 106.0 107.0 108.0 109.0 110.0 111.0 112.0\n## [13] 113.0 114.0 115.0 116.0 117.0 118.0 119.0 110.5 111.5\nsessionInfo()## R version 4.1.1 (2021-08-10)\n## Platform: aarch64-apple-darwin20 (64-bit)\n## Running under: macOS Monterey 12.4\n## \n## Matrix products: default\n## BLAS:   /Library/Frameworks/R.framework/Versions/4.1-arm64/Resources/lib/libRblas.0.dylib\n## LAPACK: /Library/Frameworks/R.framework/Versions/4.1-arm64/Resources/lib/libRlapack.dylib\n## \n## locale:\n## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n## \n## attached base packages:\n## [1] stats     graphics  grDevices utils     datasets  methods   base     \n## \n## loaded via a namespace (and not attached):\n##  [1] jquerylib_0.1.4  pillar_1.7.0     compiler_4.1.1   bslib_0.3.1     \n##  [5] tools_4.1.1      downlit_0.4.0    digest_0.6.29    memoise_2.0.1   \n##  [9] jsonlite_1.7.3   evaluate_0.15    lifecycle_1.0.1  tibble_3.1.6    \n## [13] gtable_0.3.0     pkgconfig_2.0.3  rlang_1.0.2      DBI_1.1.2       \n## [17] cli_3.2.0        rstudioapi_0.13  yaml_2.2.1       xfun_0.31       \n## [21] fastmap_1.1.0    stringr_1.4.0    xml2_1.3.3       dplyr_1.0.9     \n## [25] knitr_1.39       fs_1.5.2         generics_0.1.2   vctrs_0.4.1     \n## [29] sass_0.4.0       grid_4.1.1       tidyselect_1.1.2 glue_1.6.1      \n## [33] R6_2.5.1         fansi_1.0.2      rmarkdown_2.14   bookdown_0.27   \n## [37] ggplot2_3.3.6    purrr_0.3.4      magrittr_2.0.3   scales_1.1.1    \n## [41] ellipsis_0.3.2   htmltools_0.5.2  assertthat_0.2.1 colorspace_2.0-3\n## [45] utf8_1.2.2       stringi_1.7.6    munsell_0.5.0    cachem_1.0.6    \n## [49] crayon_1.5.0"},{"path":"getting-data-into-r.html","id":"getting-data-into-r","chapter":"2 Getting Data into R","heading":"2 Getting Data into R","text":"Read data","code":"\ninstall.packages(\"dplyr\",repos = \"https://cran.us.r-project.org\")\ninstall.packages(\"tidyr\",repos = \"https://cran.us.r-project.org\")\ninstall.packages(\"stringr\",repos = \"https://cran.us.r-project.org\")\ninstall.packages(\"lubridate\",repos = \"https://cran.us.r-project.org\")\ninstall.packages(\"readr\",repos = \"https://cran.us.r-project.org\")\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(stringr)\nlibrary(lubridate)\nlibrary(readr)\nurlfile02a=\"https://raw.githubusercontent.com/apicellap/data/main/compensation.csv\"\ncompensation<-read.csv(url(urlfile02a))\nhead(compensation)##    Root Fruit  Grazing\n## 1 6.225 59.77 Ungrazed\n## 2 6.487 60.98 Ungrazed\n## 3 4.919 14.73 Ungrazed\n## 4 5.130 19.28 Ungrazed\n## 5 5.417 34.25 Ungrazed\n## 6 5.359 35.53 Ungrazed"},{"path":"getting-data-into-r.html","id":"checking-that-your-data-are-your-data","chapter":"2 Getting Data into R","heading":"2.1 Checking that your data are your data","text":"Generate names columns/variables console:Produce number observations (rows column) followed # variables:Review structure data:","code":"\nnames(compensation)## [1] \"Root\"    \"Fruit\"   \"Grazing\"\ndim(compensation) ## [1] 40  3\nstr(compensation)## 'data.frame':    40 obs. of  3 variables:\n##  $ Root   : num  6.22 6.49 4.92 5.13 5.42 ...\n##  $ Fruit  : num  59.8 61 14.7 19.3 34.2 ...\n##  $ Grazing: chr  \"Ungrazed\" \"Ungrazed\" \"Ungrazed\" \"Ungrazed\" ..."},{"path":"getting-data-into-r.html","id":"appendix-advanced-activity-dealing-with-untidy-data","chapter":"2 Getting Data into R","heading":"2.2 Appendix advanced activity: dealing with untidy data","text":"Review data structure:dataset poorly constructedEliminate extra (37th) row dataset:filter function programmed capture every row variable, ‘Bottle’, contains textCreate new variables assort data :Remove ‘X’, precedes date observation:Display unique dates:Reformat dates universally recognized:separate() Separates information present one column multiple new columnsunite() Puts information several columns one columnrbind() Puts datasets exactly columns togethercbind() Combines two datasets exactly columns togetherfull_join() Joins two datasets one columns commonmerge() function full_join() base package","code":"\nurlfile02b=\"https://raw.githubusercontent.com/apicellap/data/main/nasty%20format.csv\"\nnasty.format<-read.csv(url(urlfile02b))\nhead(nasty.format)##      Species Bottle Temp X1.2.13 X2.2.13 X3.2.13 X4.2.13 X6.2.13 X8.2.13\n## 1 P.caudatum  7-P.c   22   100.0    58.8    67.5     6.8    0.93    0.39\n## 2 P.caudatum  8-P.c   22    62.5    71.3    67.5     7.9    0.90    0.36\n## 3 P.caudatum  9-P.c   22    75.0    72.5    62.3     7.9    0.88    0.25\n## 4 P.caudatum 22-P.c   20    75.0    73.8    76.3    31.3    3.12    1.01\n## 5 P.caudatum 23-P.c   20    50.0      NA    81.3    32.5    3.75    1.06\n## 6 P.caudatum 24-P.c   20    87.5      NA    62.5    28.8    3.12    1.00\n##   X10.2.13 X12.2.13\n## 1     0.19     0.46\n## 2     0.16     0.34\n## 3     0.23     0.31\n## 4     0.56     0.50\n## 5     0.49     0.38\n## 6     0.41     0.46\nstr(nasty.format)## 'data.frame':    37 obs. of  11 variables:\n##  $ Species : chr  \"P.caudatum\" \"P.caudatum\" \"P.caudatum\" \"P.caudatum\" ...\n##  $ Bottle  : chr  \"7-P.c\" \"8-P.c\" \"9-P.c\" \"22-P.c\" ...\n##  $ Temp    : int  22 22 22 20 20 20 15 15 15 22 ...\n##  $ X1.2.13 : num  100 62.5 75 75 50 87.5 75 50 75 37.5 ...\n##  $ X2.2.13 : num  58.8 71.3 72.5 73.8 NA NA NA NA NA 52.5 ...\n##  $ X3.2.13 : num  67.5 67.5 62.3 76.3 81.3 62.5 90 78.8 78.3 23.8 ...\n##  $ X4.2.13 : num  6.8 7.9 7.9 31.3 32.5 28.8 72.5 92.5 77.5 1.25 ...\n##  $ X6.2.13 : num  0.93 0.9 0.88 3.12 3.75 ...\n##  $ X8.2.13 : num  0.39 0.36 0.25 1.01 1.06 1 67.5 72.5 60 0.96 ...\n##  $ X10.2.13: num  0.19 0.16 0.23 0.56 0.49 0.41 37.5 52.5 60 0.33 ...\n##  $ X12.2.13: num  0.46 0.34 0.31 0.5 0.38 ...\nnasty.format<-filter(nasty.format, Bottle !=\"\") # '!=' symbol means '≠' \ntail(nasty.format)##         Species Bottle Temp X1.2.13 X2.2.13 X3.2.13 X4.2.13 X6.2.13 X8.2.13\n## 31 S. fonticola     19   20    25.0    87.5    85.0    98.8   78.75   71.25\n## 32 S. fonticola     20   20    87.5    63.8    81.3    76.3   72.50   85.00\n## 33 S. fonticola     21   20    50.0    77.5    83.8    97.5   68.75   71.25\n## 34 S. fonticola     34   15    50.0      NA   101.3    93.8   70.00   91.25\n## 35 S. fonticola     35   15    62.5      NA    65.0    72.5   61.25   72.50\n## 36 S. fonticola     36   15   112.5      NA    76.3    67.5   61.25   77.50\n##    X10.2.13 X12.2.13\n## 31     68.8   101.25\n## 32     72.5    85.00\n## 33     60.0    98.75\n## 34     76.3    80.00\n## 35     66.3   102.50\n## 36     91.3    77.50\ntidy_data <- gather(nasty.format, \n                    Date, Abundance, #the variables to be created \n                    4:11) #column headers that are dates in the nasty.format dataframe \nhead(tidy_data)##      Species Bottle Temp    Date Abundance\n## 1 P.caudatum  7-P.c   22 X1.2.13     100.0\n## 2 P.caudatum  8-P.c   22 X1.2.13      62.5\n## 3 P.caudatum  9-P.c   22 X1.2.13      75.0\n## 4 P.caudatum 22-P.c   20 X1.2.13      75.0\n## 5 P.caudatum 23-P.c   20 X1.2.13      50.0\n## 6 P.caudatum 24-P.c   20 X1.2.13      87.5\ntidy_data <- mutate(tidy_data, Date=substr(Date,2,20))\nhead(tidy_data)##      Species Bottle Temp   Date Abundance\n## 1 P.caudatum  7-P.c   22 1.2.13     100.0\n## 2 P.caudatum  8-P.c   22 1.2.13      62.5\n## 3 P.caudatum  9-P.c   22 1.2.13      75.0\n## 4 P.caudatum 22-P.c   20 1.2.13      75.0\n## 5 P.caudatum 23-P.c   20 1.2.13      50.0\n## 6 P.caudatum 24-P.c   20 1.2.13      87.5\nunique(\n  tidy_data$Date) #this says use the observations in the variable 'Date' in the 'tidy_data' dataframe## [1] \"1.2.13\"  \"2.2.13\"  \"3.2.13\"  \"4.2.13\"  \"6.2.13\"  \"8.2.13\"  \"10.2.13\"\n## [8] \"12.2.13\"\ntidy_data <-mutate(tidy_data, Date=dmy(Date))\nhead(tidy_data)##      Species Bottle Temp       Date Abundance\n## 1 P.caudatum  7-P.c   22 2013-02-01     100.0\n## 2 P.caudatum  8-P.c   22 2013-02-01      62.5\n## 3 P.caudatum  9-P.c   22 2013-02-01      75.0\n## 4 P.caudatum 22-P.c   20 2013-02-01      75.0\n## 5 P.caudatum 23-P.c   20 2013-02-01      50.0\n## 6 P.caudatum 24-P.c   20 2013-02-01      87.5"},{"path":"data-management-and-manipulation.html","id":"data-management-and-manipulation","chapter":"3 Data Management and Manipulation","heading":"3 Data Management and Manipulation","text":"Read dataSummarize data variable:","code":"\ninstall.packages(\"dplyr\",repos = \"https://cran.us.r-project.org\")\ninstall.packages(\"tidyr\",repos = \"https://cran.us.r-project.org\")\ninstall.packages(\"stringr\",repos = \"https://cran.us.r-project.org\")\ninstall.packages(\"lubridate\",repos = \"https://cran.us.r-project.org\")\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(stringr)\nlibrary(lubridate)\nurlfile03a=\"https://raw.githubusercontent.com/apicellap/data/main/compensation.csv\"\ncompensation<-read.csv(url(urlfile03a))\nhead(compensation)##    Root Fruit  Grazing\n## 1 6.225 59.77 Ungrazed\n## 2 6.487 60.98 Ungrazed\n## 3 4.919 14.73 Ungrazed\n## 4 5.130 19.28 Ungrazed\n## 5 5.417 34.25 Ungrazed\n## 6 5.359 35.53 Ungrazed\n summary(compensation)##       Root            Fruit          Grazing         \n##  Min.   : 4.426   Min.   : 14.73   Length:40         \n##  1st Qu.: 6.083   1st Qu.: 41.15   Class :character  \n##  Median : 7.123   Median : 60.88   Mode  :character  \n##  Mean   : 7.181   Mean   : 59.41                     \n##  3rd Qu.: 8.510   3rd Qu.: 76.19                     \n##  Max.   :10.253   Max.   :116.05"},{"path":"data-management-and-manipulation.html","id":"subsetting","chapter":"3 Data Management and Manipulation","heading":"3.1 Subsetting","text":"Create new dataframe comprised specific variable(s):Select columns except one:Create new dataframe comrpised specific variable(s) except ‘Root’:Create new dataframe comprised list variables:Filter data set observations TRUE:Grab observations Fruit equal 80:Grab observations Fruit ≤ 80; can also use < symbol less :Grab observations Fruit greater 95 less 15:Grab observations Fruit greater 50 less 55:Order data Fruit lowest highest observation:Create new dataframe filters observations Fruit values 80\ncontains corresponding Root values:","code":"\nhead(select(compensation,\n           Fruit))##   Fruit\n## 1 59.77\n## 2 60.98\n## 3 14.73\n## 4 19.28\n## 5 34.25\n## 6 35.53\nhead(select(compensation, -Root))##   Fruit  Grazing\n## 1 59.77 Ungrazed\n## 2 60.98 Ungrazed\n## 3 14.73 Ungrazed\n## 4 19.28 Ungrazed\n## 5 34.25 Ungrazed\n## 6 35.53 Ungrazed\nhead(slice(compensation, 2:10))##    Root Fruit  Grazing\n## 1 6.487 60.98 Ungrazed\n## 2 4.919 14.73 Ungrazed\n## 3 5.130 19.28 Ungrazed\n## 4 5.417 34.25 Ungrazed\n## 5 5.359 35.53 Ungrazed\n## 6 7.614 87.73 Ungrazed\nhead(slice(compensation, c(2,3,10)))##    Root Fruit  Grazing\n## 1 6.487 60.98 Ungrazed\n## 2 4.919 14.73 Ungrazed\n## 3 6.930 64.34 Ungrazed\nfilter(compensation, Fruit == 80) ## [1] Root    Fruit   Grazing\n## <0 rows> (or 0-length row.names)\nhead(filter(compensation, Fruit !=80))##    Root Fruit  Grazing\n## 1 6.225 59.77 Ungrazed\n## 2 6.487 60.98 Ungrazed\n## 3 4.919 14.73 Ungrazed\n## 4 5.130 19.28 Ungrazed\n## 5 5.417 34.25 Ungrazed\n## 6 5.359 35.53 Ungrazed\nhead(filter(compensation, Fruit <=80))##    Root Fruit  Grazing\n## 1 6.225 59.77 Ungrazed\n## 2 6.487 60.98 Ungrazed\n## 3 4.919 14.73 Ungrazed\n## 4 5.130 19.28 Ungrazed\n## 5 5.417 34.25 Ungrazed\n## 6 5.359 35.53 Ungrazed\nhead(filter(compensation, Fruit >95|Fruit<15))##     Root  Fruit  Grazing\n## 1  4.919  14.73 Ungrazed\n## 2 10.253 116.05   Grazed\n## 3  6.106  14.95   Grazed\n## 4  9.844 105.07   Grazed\n## 5  9.351  98.47   Grazed\nhead(filter(compensation, Fruit >50 & Fruit<55))##    Root Fruit  Grazing\n## 1 6.248 52.92 Ungrazed\n## 2 6.013 53.61 Ungrazed\n## 3 5.928 54.86 Ungrazed\n## 4 7.354 50.08   Grazed\n## 5 8.158 52.26   Grazed\nhead(arrange(compensation, Fruit))##    Root Fruit  Grazing\n## 1 4.919 14.73 Ungrazed\n## 2 6.106 14.95   Grazed\n## 3 4.426 18.89 Ungrazed\n## 4 5.130 19.28 Ungrazed\n## 5 4.975 24.25 Ungrazed\n## 6 5.451 32.35 Ungrazed\nhead(select(filter(compensation, Fruit>80), Root))##     Root\n## 1  7.614\n## 2  7.001\n## 3 10.253\n## 4  9.039\n## 5  8.988\n## 6  8.975"},{"path":"data-management-and-manipulation.html","id":"calculating-summary-statistics-about-groups-of-your-data","chapter":"3 Data Management and Manipulation","heading":"3.2 Calculating summary statistics about groups of your data","text":"Perform summary analyses dataframe:Additional summary functions create new dataframe encompass calculations:","code":"\nsummarise(\n  group_by(compensation, Grazing), #access the dataframe, target Grazing to be the grouping variable \n  meanFruit = mean(Fruit)) #creates the object, meanFruit which is the mean of the data in the Fruit variable## # A tibble: 2 × 2\n##   Grazing  meanFruit\n##   <chr>        <dbl>\n## 1 Grazed        67.9\n## 2 Ungrazed      50.9\nmean.fruit<-summarise(\n  group_by(compensation, Grazing), \n  meanFruit = mean(Fruit), sdfruit =sd(Fruit)) #multiple statistics can be calculated within summarise \nmean.fruit## # A tibble: 2 × 3\n##   Grazing  meanFruit sdfruit\n##   <chr>        <dbl>   <dbl>\n## 1 Grazed        67.9    25.0\n## 2 Ungrazed      50.9    21.8\nx <- sum(with(compensation, Grazing == \"Grazed\")) #counts number of observations for variable when it = Grazed \nx## [1] 20\nSE.mean.fruit<-summarise(\n  group_by(compensation, Grazing), \n  meanFruit = mean(Fruit), \n  SEfruit =(sd(Fruit))/sqrt(x)) #multiple statistics can be calculated within summarise \nSE.mean.fruit## # A tibble: 2 × 3\n##   Grazing  meanFruit SEfruit\n##   <chr>        <dbl>   <dbl>\n## 1 Grazed        67.9    5.58\n## 2 Ungrazed      50.9    4.87"},{"path":"visualizing-your-data.html","id":"visualizing-your-data","chapter":"4 Visualizing your data","heading":"4 Visualizing your data","text":"","code":""},{"path":"visualizing-your-data.html","id":"the-first-step-in-every-data-analysis---making-a-picture","chapter":"4 Visualizing your data","heading":"4.1 The first step in every data analysis - making a picture","text":"Read dataView dataframe & read variables + first observations horizontally:","code":"\ninstall.packages(\"ggplot2\",  repos = \"https://cran.us.r-project.org\")\ninstall.packages(\"dplyr\",  repos = \"https://cran.us.r-project.org\")\nlibrary(ggplot2)\nlibrary(dplyr)\nurlfile04a=\"https://raw.githubusercontent.com/apicellap/data/main/compensation.csv\"\ncompensation<-read.csv(url(urlfile04a))\nglimpse(compensation) ## Rows: 40\n## Columns: 3\n## $ Root    <dbl> 6.225, 6.487, 4.919, 5.130, 5.417, 5.359, 7.614, 6.352, 4.975,…\n## $ Fruit   <dbl> 59.77, 60.98, 14.73, 19.28, 34.25, 35.53, 87.73, 63.21, 24.25,…\n## $ Grazing <chr> \"Ungrazed\", \"Ungrazed\", \"Ungrazed\", \"Ungrazed\", \"Ungrazed\", \"U…"},{"path":"visualizing-your-data.html","id":"ggplot2-a-grammar-for-graphics","chapter":"4 Visualizing your data","heading":"4.2 ggplot2: a grammar for graphics","text":"Create base plot:Render background white instead gray:Add x y axis titles:","code":"\nbase_plot <-ggplot(compensation, aes(x = Root, y = Fruit, \n                                colour=Grazing)) + #colour: for the two levels of the categorical variable, Grazing\n  geom_point()                                       \nbase_plot\nbase_plot + theme_bw()\nbase_plot + \n  theme_bw() + \n  geom_point(\n    size = 5) #alter size of datapoints in scatterplot \nbase_plot + theme_bw() + geom_point(size = 5) + \n    xlab(\"Root Biomass\") + \n  ylab(\"Fruit Production\") "},{"path":"visualizing-your-data.html","id":"box-and-whisker-plots","chapter":"4 Visualizing your data","heading":"4.3 Box and whisker plots","text":"","code":"\nbase_plot2 <- ggplot(compensation, aes(x = Grazing, y = Fruit)) + \n  geom_boxplot() +  \n  geom_point(\n    size = 4, #size of point\n    colour = 'lightgrey', #color of point\n    alpha = 0.5) +         #transparency of point \n  xlab(\"Grazing treatment\") + \n  ylab(\"Fruit Production\") + \n  theme_bw() \nbase_plot2"},{"path":"visualizing-your-data.html","id":"distributions-making-histograms-of-numeric-variables","chapter":"4 Visualizing your data","heading":"4.4 Distributions: making histograms of numeric variables","text":"","code":"\nggplot(compensation, aes(x=Fruit))+\n  geom_histogram(bins=15)  #bins defines how many histogram bins there are \nggplot(compensation, aes(x=Fruit))+\n  geom_histogram(bins=15) + \n  facet_wrap(~Grazing) #facet_wrap() allows you to put the plots next to each other, a variable must be specified "},{"path":"introduction-to-statistics-in-r.html","id":"introduction-to-statistics-in-r","chapter":"5 Introduction to Statistics in R","heading":"5 Introduction to Statistics in R","text":"View data structure:","code":"\ninstall.packages(\"ggplot2\",  repos = \"https://cran.us.r-project.org\")\ninstall.packages(\"dplyr\",  repos = \"https://cran.us.r-project.org\")\ninstall.packages(\"ggfortify\",  repos = \"https://cran.us.r-project.org\")\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(ggfortify)\nurlfile05a=\"https://raw.githubusercontent.com/apicellap/data/main/ladybirds_morph_colour.csv\"\nlady<-read.csv(url(urlfile05a))\nhead(lady)##   Habitat Site morph_colour number\n## 1   Rural   R1        black     10\n## 2   Rural   R2        black      3\n## 3   Rural   R3        black      4\n## 4   Rural   R4        black      7\n## 5   Rural   R5        black      6\n## 6   Rural   R1          red     15\nstr(lady)## 'data.frame':    20 obs. of  4 variables:\n##  $ Habitat     : chr  \"Rural\" \"Rural\" \"Rural\" \"Rural\" ...\n##  $ Site        : chr  \"R1\" \"R2\" \"R3\" \"R4\" ...\n##  $ morph_colour: chr  \"black\" \"black\" \"black\" \"black\" ...\n##  $ number      : int  10 3 4 7 6 15 18 9 12 16 ..."},{"path":"introduction-to-statistics-in-r.html","id":"chi2-contingency-table-analysis","chapter":"5 Introduction to Statistics in R","heading":"5.1 \\(\\chi\\)\\(^{2}\\) contingency table analysis","text":"Create new dataframe, totals:Create bar chart:Null hypothesis: association color birds habitat\nopinion: data suggest higher proportion colored birds industrial habitat. reject null hypothesis (pre-stats)\nrigorously test , chi-squared test must performed\nopinion: data suggest higher proportion colored birds industrial habitat. reject null hypothesis (pre-stats)rigorously test , chi-squared test must performed","code":"\ntotals <- lady %>% #working with this dataframe\n  group_by(Habitat, morph_colour) %>% #we want to represent these groups in the dataframe\n  summarise(total.number = sum(number)) #add up the numbers of each group using the new object total.number## `summarise()` has grouped output by 'Habitat'. You can override using the\n## `.groups` argument.\ntotals## # A tibble: 4 × 3\n## # Groups:   Habitat [2]\n##   Habitat    morph_colour total.number\n##   <chr>      <chr>               <int>\n## 1 Industrial black                 115\n## 2 Industrial red                    85\n## 3 Rural      black                  30\n## 4 Rural      red                    70\nbase_plot<-ggplot(totals, aes(x=Habitat, y=total.number,\n                  fill = morph_colour)) + #fill is used when there is something like a bar that can be filled with color \n                                          #if this were color = morph_colour, then the argument would affect the bar's outline\n  geom_bar(\n    stat = 'identity', #this tells ggplot not to calculate anything from the data and just display the data as they are in the dataframe\n    position = 'dodge' #this is request to put the two bars in each Habitat group next to each other \n                       #if it's not used, a stacked barplot would be printed \n  ) \nbase_plot\nbase_plot +   \n  scale_fill_manual(values = c(black = \"black\", red = \"red\")) #the text in \"\" are the colors we are instructing R to fill the bars with "},{"path":"introduction-to-statistics-in-r.html","id":"making-the-chi2-test","chapter":"5 Introduction to Statistics in R","heading":"5.2 Making the \\(\\chi\\)\\(^{2}\\) Test","text":"Use xtabs() function generate contingency table:Perform \\(\\chi\\)\\(^{2}\\) test matrix:p value 0.00001239 - probability pattern arose chance.\nlower 0.05, can reject null hypothesis\nlower 0.05, can reject null hypothesis","code":"\nlady.mat <-xtabs(                     #function converts dataframe into a matrix, which is different from a dataframe\n                  number ~ Habitat + morph_colour, #cross-tabulate the number of column counts in the dataframe by the Habitat and morph_colour variables\n                 data = lady) \nlady.mat##             morph_colour\n## Habitat      black red\n##   Industrial   115  85\n##   Rural         30  70\nlady.chi<-chisq.test(lady.mat) #chi squared test function performed on matrix \nlady.chi## \n##  Pearson's Chi-squared test with Yates' continuity correction\n## \n## data:  lady.mat\n## X-squared = 19.103, df = 1, p-value = 1.239e-05\nnames(lady.chi) #can examine all of the parts of the test mechanics ## [1] \"statistic\" \"parameter\" \"p.value\"   \"method\"    \"data.name\" \"observed\" \n## [7] \"expected\"  \"residuals\" \"stdres\""},{"path":"introduction-to-statistics-in-r.html","id":"two-sample-t-test","chapter":"5 Introduction to Statistics in R","heading":"5.3 Two-sample t-test","text":"two-sample t-test compares means two groups numeric valuesIt appropriate sample sizes two groups smallThe analysis makes following assumptions data:\ndata normally distributed\nvariances data equivalent\ndata normally distributedThe variances data equivalent","code":"\nurlfile05b=\"https://raw.githubusercontent.com/apicellap/data/main/ozone.csv\"\nozone<-read.csv(url(urlfile05b))\nglimpse(ozone)## Rows: 20\n## Columns: 3\n## $ Ozone           <dbl> 61.7, 64.0, 72.4, 56.8, 52.4, 44.8, 70.4, 67.6, 68.8, …\n## $ Garden.location <chr> \"West\", \"West\", \"West\", \"West\", \"West\", \"West\", \"West\"…\n## $ Garden.ID       <chr> \"G1\", \"G2\", \"G3\", \"G4\", \"G5\", \"G6\", \"G7\", \"G8\", \"G9\", …"},{"path":"introduction-to-statistics-in-r.html","id":"the-first-step-plot-your-data","chapter":"5 Introduction to Statistics in R","heading":"5.3.1 The first step: Plot your data","text":"Create histograms data, Garden.location variable:graph shows assumptions normality equality variance met\nR functions evaluate aspects rigorously \nR functions evaluate aspects rigorously tooCount number observations variable ‘East’:Plot ozone data barplot:Plot ozone data boxplot:null hypothesis: difference ozone levels East West garden locationsmy opinion based boxplot - reject null hypothesis","code":"\nggplot(ozone, aes(x=Ozone))+ #since this is a histogram, x must be a continuous variable; cannot be categorical \n  geom_histogram(binwidth=10) + \n  facet_wrap(~Garden.location, #Divide data up into groups by this variable \n            ncol=1 ) +  #stacks the graphs on top of each other - 1 column \n  theme_bw()\nx<-sum(with(ozone, Garden.location == \"East\")) \nx## [1] 10\nsummary<-ozone %>% \n  group_by(Garden.location) %>% \n  summarise(mean = mean(Ozone), SE = (sd(Ozone))/sqrt(x))\nsummary## # A tibble: 2 × 3\n##   Garden.location  mean    SE\n##   <chr>           <dbl> <dbl>\n## 1 East             77.3  2.49\n## 2 West             61.3  2.87\nOzBrP<-ggplot(summary, aes(x = Garden.location, y = mean)) + #x defined as grazing treatment, y as fruit production\n  geom_col() + \n  geom_errorbar(aes(x=Garden.location, ymin=mean -SE, ymax=mean*1+SE, width=.2),\n                                            position = 'dodge')\nOzBrP\nOzBxP <-ggplot(ozone, aes(x = Garden.location, y = Ozone)) + \n  geom_boxplot()\nOzBxP"},{"path":"introduction-to-statistics-in-r.html","id":"two-sample-t-test-analysis","chapter":"5 Introduction to Statistics in R","heading":"5.3.2 Two sample t-test analysis","text":"Perform two sample t-test ozone dataset:default two sample t-test Welch’s version\nWelch version, assumption equal variance relaxed allows test equal variance\nWelch version, assumption equal variance relaxed allows test equal varianceThe GSwR authors suggest testing equal variancenote regarding Confidence interval (CI): line 95% CI 8.1-24.1. Since range include 0 says means statistically different . congruent p value t-test","code":"\nt.test(Ozone ~ Garden.location, #expression means do ozone levels vary as a function of location? That's how the ~ reads \n       data = ozone)## \n##  Welch Two Sample t-test\n## \n## data:  Ozone by Garden.location\n## t = 4.2363, df = 17.656, p-value = 0.0005159\n## alternative hypothesis: true difference in means between group East and group West is not equal to 0\n## 95 percent confidence interval:\n##   8.094171 24.065829\n## sample estimates:\n## mean in group East mean in group West \n##              77.34              61.26"},{"path":"introduction-to-statistics-in-r.html","id":"linear-models","chapter":"5 Introduction to Statistics in R","heading":"5.4 Linear models","text":"Linear models class analyses include regression, multiple regression, ANOVA, ANCOVA\ncentered around similiar framework ideas common set assumptions data like idea data normally distributed\ncentered around similiar framework ideas common set assumptions data like idea data normally distributed","code":""},{"path":"introduction-to-statistics-in-r.html","id":"simple-linear-regression","chapter":"5 Introduction to Statistics in R","heading":"5.5 Simple linear regression","text":"section focuses dataset compares plant growth rates soil moisture contentThe response (dependent) variable plant growth ratePlant growth rate plotted explanatory (independent) variable, soil moisture content\nvariable continuous, numeric variable categories\nvariable continuous, numeric variable categoriesRead view structure data:","code":"\nurlfile05c=\"https://raw.githubusercontent.com/apicellap/data/main/plant.growth.rate.csv\"\nplant_gr<-read.csv(url(urlfile05c))\nglimpse(plant_gr) #two continuous (numeric) variables. they have no categories ## Rows: 50\n## Columns: 2\n## $ soil.moisture.content <dbl> 0.4696876, 0.5413106, 1.6979915, 0.8255799, 0.85…\n## $ plant.growth.rate     <dbl> 21.31695, 27.03072, 38.98937, 30.19529, 37.06547…"},{"path":"introduction-to-statistics-in-r.html","id":"getting-and-plotting-the-data","chapter":"5 Introduction to Statistics in R","heading":"5.5.1 Getting and plotting the data","text":"Plot plant growth (pg) data:Plot shows probably positive linear relationship two variables\nslope 15 mm/week\npreliminary analysis: probably reject null hypothesis soil moisture affect plant growth\nslope 15 mm/weekpreliminary analysis: probably reject null hypothesis soil moisture affect plant growth","code":"\nggplot(plant_gr,\n       aes(x=soil.moisture.content, y=plant.growth.rate)) +\n  geom_point()+ \n  ylab(\"Plant Growth Rate (mm/week)\") + \n  theme_bw()"},{"path":"introduction-to-statistics-in-r.html","id":"making-a-simple-linear-regression-happen","chapter":"5 Introduction to Statistics in R","heading":"5.5.2 Making a simple linear regression happen","text":"Create linear model:","code":"\nmodel_pgr <- lm(plant.growth.rate ~ soil.moisture.content, data = plant_gr) #plant growth rate is a function of soil moisture content\nmodel_pgr## \n## Call:\n## lm(formula = plant.growth.rate ~ soil.moisture.content, data = plant_gr)\n## \n## Coefficients:\n##           (Intercept)  soil.moisture.content  \n##                 19.35                  12.75"},{"path":"introduction-to-statistics-in-r.html","id":"assumptions-first","chapter":"5 Introduction to Statistics in R","heading":"5.5.3 Assumptions first","text":"Check assumptions ggfortify:ggfortify plots:\nTop left - informs us whether line appropriate fit data; flat line means model good fit. Humps/valleys -> poor fit\nTop right - dots = residuals; dashes line = expectation normal distribution. Better tool histogram assess normal distribution\nBottom left - evaluates assumption equal variance. linear models assume variance constant predicted values response variable. pattern\nBottom right - evaluates leverage. Used detect influential datapoints shift gradient expected + also outliers\nTop left - informs us whether line appropriate fit data; flat line means model good fit. Humps/valleys -> poor fitTop right - dots = residuals; dashes line = expectation normal distribution. Better tool histogram assess normal distributionBottom left - evaluates assumption equal variance. linear models assume variance constant predicted values response variable. patternBottom right - evaluates leverage. Used detect influential datapoints shift gradient expected + also outliersnull hypothesis: soil moisture effect plant growth","code":"\nautoplot(model_pgr, \n         smooth.colour = NA)"},{"path":"introduction-to-statistics-in-r.html","id":"now-the-interpretation","chapter":"5 Introduction to Statistics in R","heading":"5.5.4 Now the interpretation","text":"Produce sum squares table:Output:Large F value indicates error variance small relative variance attributed explanatory variable\nleads tiny p value.\ngood indications effect seen data isn’t result chance\n\nleads tiny p value.\ngood indications effect seen data isn’t result chance\ngood indications effect seen data isn’t result chanceProduce summary table:produces table estimates coefficients line modelthe slope associated explanatory variable (soil moisture) - values associated differences plant growth rateSuperimpose linear model onto plot:","code":"\nanova(model_pgr)## Analysis of Variance Table\n## \n## Response: plant.growth.rate\n##                       Df  Sum Sq Mean Sq F value    Pr(>F)    \n## soil.moisture.content  1 2521.15 2521.15  156.08 < 2.2e-16 ***\n## Residuals             48  775.35   16.15                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nsummary(model_pgr) ## \n## Call:\n## lm(formula = plant.growth.rate ~ soil.moisture.content, data = plant_gr)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -8.9089 -3.0747  0.2261  2.6567  8.9406 \n## \n## Coefficients:\n##                       Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)             19.348      1.283   15.08   <2e-16 ***\n## soil.moisture.content   12.750      1.021   12.49   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 4.019 on 48 degrees of freedom\n## Multiple R-squared:  0.7648, Adjusted R-squared:  0.7599 \n## F-statistic: 156.1 on 1 and 48 DF,  p-value: < 2.2e-16\nggplot(plant_gr,\n       aes(x=soil.moisture.content, y=plant.growth.rate)) +\n  geom_point()+ \n  geom_smooth(method = 'lm') + #put a linear-model fitted line and the standard error of the fit using flash transparent gray onto graph \n  ylab(\"Plant Growth Rate (mm/week)\") + \n  theme_bw()## `geom_smooth()` using formula 'y ~ x'"},{"path":"introduction-to-statistics-in-r.html","id":"analysis-of-variance-the-one-way-anova","chapter":"5 Introduction to Statistics in R","heading":"5.6 Analysis of variance: the one-way ANOVA","text":"one-way ANOVA similiar previous example two-sample t-test one key difference:\nexplanatory variable one-way ANOVA categorical variable (factor)\nexplanatory variable one-way ANOVA categorical variable (factor)waterflea dataset - ask:\nwhether parasites alter waterflea growth rates\nwhether three parasittes reduces growth rates relative control parasite\nwhether parasites alter waterflea growth rateswhether three parasittes reduces growth rates relative control parasitePlot daphnia data:Visualization takeaways:\nsubstantial variation among parasite groups\ncontrol group highest growth rate\nlikely overall effect parasites growth rate\nmay order impacts different parasites growth rates: P. ramosa < M. bicuspidata < P. perplexa\nsubstantial variation among parasite groupsThe control group highest growth rateThere likely overall effect parasites growth rateThere may order impacts different parasites growth rates: P. ramosa < M. bicuspidata < P. perplexaCreate model:Check assumptions:assumption-checking plots:\nfigures suggest assumptions fine\nEven upper right plot, Q-Q plot, within bounds expected variation\nfigures suggest assumptions fineEven upper right plot, Q-Q plot, within bounds expected variationProduce anova table model:one-way anova, null hypothesis groups come populations (statistically) mean\nF-value quantifies likely true\nF value ratio group variation: within group variation\nlarge F value means group variation much larger\n\n\nF-value quantifies likely true\nF value ratio group variation: within group variation\nlarge F value means group variation much larger\n\nF value ratio group variation: within group variation\nlarge F value means group variation much larger\nlarge F value means group variation much largerOutput:table coefficients:\nlabelled ‘(Intercept)’ control\nR tends list things alphabetical order\nlevels explanatory variable, ‘control’ first alphabetically\ncontext, can assume (Intercept) refers first level alphabetical order - control - case\n\nTreatment contrasts report differences reference level (control case) levels\n-0.41275 difference control level parasiteMetschnikowia bicuspidata level\nwords, differences distances colored diamonds dotted black line figure 6.1 \n\nlabelled ‘(Intercept)’ controlR tends list things alphabetical order\nlevels explanatory variable, ‘control’ first alphabetically\ncontext, can assume (Intercept) refers first level alphabetical order - control - case\nlevels explanatory variable, ‘control’ first alphabeticallyIn context, can assume (Intercept) refers first level alphabetical order - control - caseTreatment contrasts report differences reference level (control case) levels\n-0.41275 difference control level parasiteMetschnikowia bicuspidata level\nwords, differences distances colored diamonds dotted black line figure 6.1 \n-0.41275 difference control level parasiteMetschnikowia bicuspidata levelIn words, differences distances colored diamonds dotted black line figure 6.1 belowDetermine means level:Manually determine difference control levels:\nFigure 5.1: Daphnia Treatment Differences\n","code":"\nurlfile05d=\"https://raw.githubusercontent.com/apicellap/data/main/Daphniagrowth.csv\"\ndaphnia<-read.csv(url(urlfile05d))\nglimpse(daphnia)## Rows: 40\n## Columns: 3\n## $ parasite    <chr> \"control\", \"control\", \"control\", \"control\", \"control\", \"co…\n## $ rep         <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, …\n## $ growth.rate <dbl> 1.0747092, 1.2659016, 1.3151563, 1.0757519, 1.1967619, 1.3…\nggplot(daphnia, aes(x = parasite, y=growth.rate)) + \n  geom_boxplot() +\n  theme_bw() + \n  coord_flip() #flips the orientation of the graph 90˚ to the right \nmodel_grow <- lm(growth.rate ~ parasite, data = daphnia)\nmodel_grow## \n## Call:\n## lm(formula = growth.rate ~ parasite, data = daphnia)\n## \n## Coefficients:\n##                       (Intercept)  parasiteMetschnikowia bicuspidata  \n##                            1.2139                            -0.4128  \n##      parasitePansporella perplexa           parasitePasteuria ramosa  \n##                           -0.1376                            -0.7317\nautoplot(model_grow, \n         smooth.colour = NA)\nanova(model_grow)## Analysis of Variance Table\n## \n## Response: growth.rate\n##           Df Sum Sq Mean Sq F value    Pr(>F)    \n## parasite   3 3.1379 1.04597  32.325 2.571e-10 ***\n## Residuals 36 1.1649 0.03236                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nsummary(model_grow)## \n## Call:\n## lm(formula = growth.rate ~ parasite, data = daphnia)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -0.41930 -0.09696  0.01408  0.12267  0.31790 \n## \n## Coefficients:\n##                                   Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)                        1.21391    0.05688  21.340  < 2e-16 ***\n## parasiteMetschnikowia bicuspidata -0.41275    0.08045  -5.131 1.01e-05 ***\n## parasitePansporella perplexa      -0.13755    0.08045  -1.710   0.0959 .  \n## parasitePasteuria ramosa          -0.73171    0.08045  -9.096 7.34e-11 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.1799 on 36 degrees of freedom\n## Multiple R-squared:  0.7293, Adjusted R-squared:  0.7067 \n## F-statistic: 32.33 on 3 and 36 DF,  p-value: 2.571e-10\nsumDat <- daphnia %>% \n  group_by(parasite) %>%\n  summarise(meanGR = mean(growth.rate))\nsumDat## # A tibble: 4 × 2\n##   parasite                  meanGR\n##   <chr>                      <dbl>\n## 1 control                    1.21 \n## 2 Metschnikowia bicuspidata  0.801\n## 3 Pansporella perplexa       1.08 \n## 4 Pasteuria ramosa           0.482\n0.8011541   -1.2139088  ## [1] -0.4127547\n1.0763551 - 1.2139088## [1] -0.1375537\n0.4822030 - 1.2139088## [1] -0.7317058\nggplot(daphnia, aes(x = parasite, y=growth.rate, color = parasite)) + \n  geom_point(size =2) + \n  geom_point(data = sumDat, aes( x = parasite, y = meanGR), shape = 18, size = 5) +\n  geom_hline(yintercept = sumDat$meanGR[1],\n             lwd=1,\n             linetype = 'dotted',\n             colour=\"black\") + \n  geom_hline(yintercept = sumDat$meanGR[1],\n             lwd=1,\n             linetype = 'dotted',\n             colour=\"black\") + \n  xlab(\"\")+\n  theme_bw() + \n  coord_flip() "},{"path":"advancing-statistics-in-r.html","id":"advancing-statistics-in-r","chapter":"6 Advancing Statistics in R","heading":"6 Advancing Statistics in R","text":"","code":"\ninstall.packages(\"ggplot2\",  repos = \"https://cran.us.r-project.org\")\ninstall.packages(\"dplyr\",  repos = \"https://cran.us.r-project.org\")\ninstall.packages(\"ggfortify\",  repos = \"https://cran.us.r-project.org\")\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(ggfortify)"},{"path":"advancing-statistics-in-r.html","id":"the-two-way-anova","chapter":"6 Advancing Statistics in R","heading":"6.1 The two-way ANOVA","text":"two-way ANOVA differs one-way version involves two categorical/explanatory variablesthe response variable two-way ANOVA may vary explanatory variables\nway varies depends explanatory variable, phenomenon known statistical interaction\nway varies depends explanatory variable, phenomenon known statistical interactionRead data:","code":"\nurlfile06a=\"https://raw.githubusercontent.com/apicellap/data/main/growth.csv\"\ngrowth.moo<-read.csv(url(urlfile06a))\nglimpse(growth.moo)## Rows: 48\n## Columns: 3\n## $ supplement <chr> \"supergain\", \"supergain\", \"supergain\", \"supergain\", \"contro…\n## $ diet       <chr> \"wheat\", \"wheat\", \"wheat\", \"wheat\", \"wheat\", \"wheat\", \"whea…\n## $ gain       <dbl> 17.37125, 16.81489, 18.08184, 15.78175, 17.70656, 18.22717,…"},{"path":"advancing-statistics-in-r.html","id":"cow-growth-data","chapter":"6 Advancing Statistics in R","heading":"6.1.1 Cow Growth data","text":"dataset deals cows different diets\ncows fed one three diets:\nwheat, oats, barley\n\ndiet enhanced one four supplements:\nsupergrain, control, supersupp, agrimore\n\ndiet combination 3 biological replicates (cows)\ncows fed one three diets:\nwheat, oats, barley\nwheat, oats, barleyeach diet enhanced one four supplements:\nsupergrain, control, supersupp, agrimore\nsupergrain, control, supersupp, agrimoreeach diet combination 3 biological replicates (cows)Coerce two variables factors:previous code chunks output alphabetical orderR always declares first level alphabetically reference levelin case supplement variable, control must made reference level\ncan accomplished using relevel() function:\ncan accomplished using relevel() function:Create summary dataframe:different supplements might growth stimulating effectsthe different supplements might growth stimulating effectsthe barley /oats diets might better stimulating growth relative wheat dietthe barley /oats diets might better stimulating growth relative wheat dietsince lines parallel , can probably rule interaction effects. means effect supplement probably depend effect dietsince lines parallel , can probably rule interaction effects. means effect supplement probably depend effect dietbut might additive effectbut might additive effectnull hypothesis: effect supplement type depend dietnull hypothesis: effect supplement type depend dietCreate model evaluate null hypothesis:function asks growth depends diet, supplement, interaction diet:supplementCheck assumptions:plot output: look okay, ideal\ntop left - pattern suggest model inappropriate\ntop right - less ideal positive negative residuals smaller expected general linear model able deal deviations normality\nbottom left - looks fine, virtually pattern\nbottom right - serious outliers, looks fine\ntop left - pattern suggest model inappropriatetop right - less ideal positive negative residuals smaller expected general linear model able deal deviations normalitybottom left - looks fine, virtually patternbottom right - serious outliers, looks fineCreate ANOVA table:diet:supplement row shows small F value p value 0.91 (way bigger 0.05)statistically significant effect contributed two variables togetherrevisit importance big F valueCreate summary table:output:\nintercept reference point table. ’s barley-control barley alphabetically first\nalready set reference control\nEstimate column difference reference level level row\nintercept reference point table. ’s barley-control barley alphabetically firstand already set reference controlthe Estimate column difference reference level level rowGenerate new summary table:Replot data standard error bars:","code":"\ngrowth.moo$supplement <-as.factor(growth.moo$supplement) \ngrowth.moo$diet <-as.factor(growth.moo$diet) \nlevels(growth.moo$diet)## [1] \"barley\" \"oats\"   \"wheat\"\nlevels(growth.moo$supplement)## [1] \"agrimore\"  \"control\"   \"supergain\" \"supersupp\"\ngrowth.moo <- mutate(growth.moo,\n                     supplement = relevel(supplement, ref = \"control\"))\nlevels(growth.moo$supplement)## [1] \"control\"   \"agrimore\"  \"supergain\" \"supersupp\"\nsumMoo <- growth.moo  %>% \n  group_by(diet,supplement) %>% \n  summarise(meanGrow = mean(gain))## `summarise()` has grouped output by 'diet'. You can override using the\n## `.groups` argument.\nsumMoo## # A tibble: 12 × 3\n## # Groups:   diet [3]\n##    diet   supplement meanGrow\n##    <fct>  <fct>         <dbl>\n##  1 barley control        23.3\n##  2 barley agrimore       26.3\n##  3 barley supergain      22.5\n##  4 barley supersupp      25.6\n##  5 oats   control        20.5\n##  6 oats   agrimore       23.3\n##  7 oats   supergain      19.7\n##  8 oats   supersupp      21.9\n##  9 wheat  control        17.4\n## 10 wheat  agrimore       19.6\n## 11 wheat  supergain      17.0\n## 12 wheat  supersupp      19.7\nggplot(sumMoo, aes(x=supplement, y=meanGrow,\n                   colour = diet,   #adds color by group\n                   group = diet)) + #\n  geom_point() +\n  geom_line() + #connects the dots in each dataset \n  theme_bw()\nmodel_cow <- lm(gain ~ diet * supplement, \n                data=growth.moo)\nmodel_cow## \n## Call:\n## lm(formula = gain ~ diet * supplement, data = growth.moo)\n## \n## Coefficients:\n##                   (Intercept)                       dietoats  \n##                    23.2966499                     -2.8029851  \n##                     dietwheat             supplementagrimore  \n##                    -5.8911317                      3.0518277  \n##           supplementsupergain            supplementsupersupp  \n##                    -0.8305263                      2.2786527  \n##   dietoats:supplementagrimore   dietwheat:supplementagrimore  \n##                    -0.2471088                     -0.8182729  \n##  dietoats:supplementsupergain  dietwheat:supplementsupergain  \n##                    -0.0001351                      0.4374395  \n##  dietoats:supplementsupersupp  dietwheat:supplementsupersupp  \n##                    -0.9120830                     -0.0158299\nautoplot(model_cow, smooth.colour = NA)\nanova(model_cow)## Analysis of Variance Table\n## \n## Response: gain\n##                 Df  Sum Sq Mean Sq F value    Pr(>F)    \n## diet             2 287.171 143.586 83.5201 2.999e-14 ***\n## supplement       3  91.881  30.627 17.8150 2.952e-07 ***\n## diet:supplement  6   3.406   0.568  0.3302    0.9166    \n## Residuals       36  61.890   1.719                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nsummary(model_cow)## \n## Call:\n## lm(formula = gain ~ diet * supplement, data = growth.moo)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -2.48756 -1.00368 -0.07452  1.03496  2.68069 \n## \n## Coefficients:\n##                                 Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)                   23.2966499  0.6555863  35.536  < 2e-16 ***\n## dietoats                      -2.8029851  0.9271390  -3.023  0.00459 ** \n## dietwheat                     -5.8911317  0.9271390  -6.354 2.34e-07 ***\n## supplementagrimore             3.0518277  0.9271390   3.292  0.00224 ** \n## supplementsupergain           -0.8305263  0.9271390  -0.896  0.37631    \n## supplementsupersupp            2.2786527  0.9271390   2.458  0.01893 *  \n## dietoats:supplementagrimore   -0.2471088  1.3111726  -0.188  0.85157    \n## dietwheat:supplementagrimore  -0.8182729  1.3111726  -0.624  0.53651    \n## dietoats:supplementsupergain  -0.0001351  1.3111726   0.000  0.99992    \n## dietwheat:supplementsupergain  0.4374395  1.3111726   0.334  0.74060    \n## dietoats:supplementsupersupp  -0.9120830  1.3111726  -0.696  0.49113    \n## dietwheat:supplementsupersupp -0.0158299  1.3111726  -0.012  0.99043    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.311 on 36 degrees of freedom\n## Multiple R-squared:  0.8607, Adjusted R-squared:  0.8182 \n## F-statistic: 20.22 on 11 and 36 DF,  p-value: 3.295e-12\nsumMoo <- growth.moo  %>% \n  group_by(diet,supplement) %>% \n  summarise(meanGrow = mean(gain),\n            seGrow = \n              sd(gain)/\n              sqrt(\n                n()))  #n() counts the number of observations in each group ## `summarise()` has grouped output by 'diet'. You can override using the\n## `.groups` argument.\n                      #side note: n() will count observations even if they have missing values\n  sumMoo        ## # A tibble: 12 × 4\n## # Groups:   diet [3]\n##    diet   supplement meanGrow seGrow\n##    <fct>  <fct>         <dbl>  <dbl>\n##  1 barley control        23.3  0.703\n##  2 barley agrimore       26.3  0.919\n##  3 barley supergain      22.5  0.771\n##  4 barley supersupp      25.6  1.06 \n##  5 oats   control        20.5  0.506\n##  6 oats   agrimore       23.3  0.613\n##  7 oats   supergain      19.7  0.349\n##  8 oats   supersupp      21.9  0.413\n##  9 wheat  control        17.4  0.460\n## 10 wheat  agrimore       19.6  0.710\n## 11 wheat  supergain      17.0  0.485\n## 12 wheat  supersupp      19.7  0.475\nggplot(sumMoo, aes(x=supplement, y=meanGrow,\n                   colour = diet,   #adds color by group\n                   group = diet)) + #\n  geom_point() +\n  geom_line() + #connects the dots in each dataset \n  geom_errorbar(aes(ymin = meanGrow - seGrow,\n                    ymax = meanGrow + seGrow), width = 0.1) + \n  theme_bw()"},{"path":"advancing-statistics-in-r.html","id":"analysis-of-covariance-ancova","chapter":"6 Advancing Statistics in R","heading":"6.2 Analysis of Covariance (ANCOVA)","text":"linear model unique combines categorical explanatory variable continuous explanatory variableRead data:dataset involves egg production limpets\n4 density conditions two production seasons\n4 density conditions two production seasonsthe response (y) variable egg productionthe independent (x) variables include:\ndensity (continuous)\nseason (categorical)\ndensity (continuous)season (categorical)study density dependent reproductionDoes density dependence egg production differ spring summer seasons?Coerce variable factor:Start plotting data:Output observations:\nlimpet density increases, seems decrease egg production\nappears seasonal difference egg production yields better spring summer\nmathematically, intercept (value egg production) density 0 higher spring\n\nlimpet density increases, seems decrease egg productionThere appears seasonal difference egg production yields better spring summer\nmathematically, intercept (value egg production) density 0 higher spring\nmathematically, intercept (value egg production) density 0 higher springThinking plot terms regression:\ny egg production\nx density\nb line crosses y axis (egg production density = 0)\nm slope egg production density relationship -\nChange egg production per unit change density - strength density dependence\ny egg productionx densityb line crosses y axis (egg production density = 0)m slope egg production density relationship -Change egg production per unit change density - strength density dependenceIn table, neither B reflect data limpet density scatterplotE also data justice slopes approximately parallelC D possible\nD best explanation data\nD best explanation dataThe difference E D presence (E) absence (D) interaction term specifies slopes different\ninteraction look like - “effect density egg production depends season”\neffect density egg production = slope value\nDepends season = values may differ depending season\n\ninteraction look like - “effect density egg production depends season”\neffect density egg production = slope value\nDepends season = values may differ depending season\neffect density egg production = slope valueDepends season = values may differ depending season","code":"\nurlfile06b=\"https://raw.githubusercontent.com/apicellap/data/main/limpet.csv\"\nlimp<-read.csv(url(urlfile06b))\nglimpse(limp)## Rows: 24\n## Columns: 3\n## $ DENSITY <int> 8, 8, 8, 8, 8, 8, 15, 15, 15, 15, 15, 15, 30, 30, 30, 30, 30, …\n## $ SEASON  <chr> \"spring\", \"spring\", \"spring\", \"summer\", \"summer\", \"summer\", \"s…\n## $ EGGS    <dbl> 2.875, 2.625, 1.750, 2.125, 1.500, 1.875, 2.600, 1.866, 2.066,…\nlimp$SEASON <-as.factor(limp$SEASON) \nis.factor(limp$SEASON) #allows you to check that the coercion worked ## [1] TRUE\nggplot(limp, aes(x = DENSITY, y = EGGS, colour=SEASON)) + #colour - gives color to the two levels of the categorical variable, Grazing\n  geom_point() +\n  scale_color_manual(values = c(spring = \"green\", summer = \"red\")) + \n  xlab(\"Limpet Density\") + \n  ylab(\"Eggs produced\") + \n  theme_bw()  "},{"path":"advancing-statistics-in-r.html","id":"constructing-the-ancova","chapter":"6 Advancing Statistics in R","heading":"6.2.1 Constructing the ANCOVA","text":"Null hypothesis: interaction term significant\nsay - differences slopes season\nextra variation explained fitting different slopes\n\nsay - differences slopes season\nextra variation explained fitting different slopes\nextra variation explained fitting different slopesFetch coefficients (intercepts slope estimates), residuals, fitted values, etc.:Check assumptions:assumptions met according figuresGenerate anova table:output:\nbig F values/small p values - DENSITY SEASON - effects significant/unlikely result chance\neffects DENSITY SEASON additive\n\nsmall F value/big p value - DENSITY:SEASON - interaction\nbig F values/small p values - DENSITY SEASON - effects significant/unlikely result chance\neffects DENSITY SEASON additive\neffects DENSITY SEASON additivesmall F value/big p value - DENSITY:SEASON - interactionGenerate summary table:Upper portion table:\nR lists things alphanumerically (spring listed summer)\nSEASONsummer difference spring summer y intercepts\nrough calculations estimated -0.756, close -0.81\nDENSITY:SEASONsummer difference slopes spring summer\nwords, change rate density dependence arises shifting spring summer\n\nsummmer, density dependence 0.003 units (egg prod/density) lower spring found statistically significant\nSummer reduces egg production compared spring, average, 0.812 eggs - significant\nR lists things alphanumerically (spring listed summer)SEASONsummer difference spring summer y interceptsMy rough calculations estimated -0.756, close -0.81DENSITY:SEASONsummer difference slopes spring summer\nwords, change rate density dependence arises shifting spring summer\nwords, change rate density dependence arises shifting spring summerIn summmer, density dependence 0.003 units (egg prod/density) lower spring found statistically significantSummer reduces egg production compared spring, average, 0.812 eggs - significantBottom coefficients table:\nAdjusted R-squared (0.6705) - means model fitted explains 67% variation egg production\nLow p value - model signficant fit data p < 0.001\nLarge F statistic\nAdjusted R-squared (0.6705) - means model fitted explains 67% variation egg productionLow p value - model signficant fit data p < 0.001Large F statistic","code":"\nlimp.mod <- lm(EGGS ~ DENSITY * SEASON, #expression says we want model to analyze a (main) effect of DENSITY,\n               #a (main) effect of SEASON, and the potential for the effect of DENSITY\n               #to depend on SEASON (interaction )\n               \n               data = limp)\n\nlimp.mod## \n## Call:\n## lm(formula = EGGS ~ DENSITY * SEASON, data = limp)\n## \n## Coefficients:\n##          (Intercept)               DENSITY          SEASONsummer  \n##             2.664166             -0.033650             -0.812282  \n## DENSITY:SEASONsummer  \n##             0.003114\nnames(limp.mod)##  [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"         \n##  [5] \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"  \n##  [9] \"contrasts\"     \"xlevels\"       \"call\"          \"terms\"        \n## [13] \"model\"\nautoplot(limp.mod,smooth.colour = NA)\nanova(limp.mod)## Analysis of Variance Table\n## \n## Response: EGGS\n##                Df Sum Sq Mean Sq F value    Pr(>F)    \n## DENSITY         1 5.0241  5.0241 30.1971 2.226e-05 ***\n## SEASON          1 3.2502  3.2502 19.5350 0.0002637 ***\n## DENSITY:SEASON  1 0.0118  0.0118  0.0711 0.7925333    \n## Residuals      20 3.3275  0.1664                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nsummary(limp.mod)## \n## Call:\n## lm(formula = EGGS ~ DENSITY * SEASON, data = limp)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -0.65468 -0.25021 -0.03318  0.28335  0.57532 \n## \n## Coefficients:\n##                       Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)           2.664166   0.234118  11.380 3.45e-10 ***\n## DENSITY              -0.033650   0.008259  -4.074 0.000591 ***\n## SEASONsummer         -0.812282   0.331092  -2.453 0.023450 *  \n## DENSITY:SEASONsummer  0.003114   0.011680   0.267 0.792533    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.4079 on 20 degrees of freedom\n## Multiple R-squared:  0.7135, Adjusted R-squared:  0.6705 \n## F-statistic:  16.6 on 3 and 20 DF,  p-value: 1.186e-05"},{"path":"advancing-statistics-in-r.html","id":"putting-the-lines-onto-the-figure","chapter":"6 Advancing Statistics in R","heading":"6.2.2 Putting the lines onto the figure","text":"need predict y values using sensible range x values\ncan use model eggs(spring) = 2.66 - 0.033 x DENSITY accomplish \ncan use model eggs(spring) = 2.66 - 0.033 x DENSITY accomplish thisBuild factorial representation variables output grid numbers:Predict y values provided x values:24 values returned , 2 seasons x 4 density treatments x 3 replicates = 24To generate new set x values use:can now embed ‘new.x’ x values predict() function:Now housekeeping:Plot data:","code":"\ncoef(limp.mod)##          (Intercept)              DENSITY         SEASONsummer \n##          2.664166462         -0.033649651         -0.812282493 \n## DENSITY:SEASONsummer \n##          0.003113571\nexpand.grid(FIRST = c(\"A\",\"B\"), SECOND = c(1,2))  ##   FIRST SECOND\n## 1     A      1\n## 2     B      1\n## 3     A      2\n## 4     B      2\npredict(limp.mod) ##         1         2         3         4         5         6         7         8 \n## 2.3949692 2.3949692 2.3949692 1.6075953 1.6075953 1.6075953 2.1594217 2.1594217 \n##         9        10        11        12        13        14        15        16 \n## 2.1594217 1.3938428 1.3938428 1.3938428 1.6546769 1.6546769 1.6546769 0.9358016 \n##        17        18        19        20        21        22        23        24 \n## 0.9358016 0.9358016 1.1499321 1.1499321 1.1499321 0.4777604 0.4777604 0.4777604\nnew.x <- expand.grid(DENSITY =              \n                       seq(from =8, to=45, #the new x values will be between 8 and 45 \n                           length.out = 10), #generates 10 new x values for each parameter \n                     SEASON = levels(limp$SEASON)) #sets the parameter as season. \nhead(new.x)##    DENSITY SEASON\n## 1  8.00000 spring\n## 2 12.11111 spring\n## 3 16.22222 spring\n## 4 20.33333 spring\n## 5 24.44444 spring\n## 6 28.55556 spring\nnew.y <- predict(limp.mod, \n                 newdata = new.x, #instructs R to use the new x values \n                 interval = 'confidence') #for confidence interval around each y value (fit) \nhead(new.y)##        fit      lwr      upr\n## 1 2.394969 2.019285 2.770654\n## 2 2.256632 1.931230 2.582034\n## 3 2.118294 1.834274 2.402315\n## 4 1.979957 1.724062 2.235852\n## 5 1.841619 1.595998 2.087241\n## 6 1.703282 1.447918 1.958646\naddThese <- data.frame(new.x, new.y) #combines the two dfs into a single one \naddThese <- rename(addThese, EGGS = fit) #changes the column name \"fit\" to EGGS \nhead(addThese)##    DENSITY SEASON     EGGS      lwr      upr\n## 1  8.00000 spring 2.394969 2.019285 2.770654\n## 2 12.11111 spring 2.256632 1.931230 2.582034\n## 3 16.22222 spring 2.118294 1.834274 2.402315\n## 4 20.33333 spring 1.979957 1.724062 2.235852\n## 5 24.44444 spring 1.841619 1.595998 2.087241\n## 6 28.55556 spring 1.703282 1.447918 1.958646\nggplot(limp, aes(x=DENSITY, y = EGGS, colour = SEASON)) + \n  geom_point(size = 2.5) + #specifies the size of the point\n  \n  geom_smooth( #adds the regression line and the CI around the fitted line;\n    #assumes that x and y are the same as already specified in ggplot\n    data = addThese, \n    aes(ymin = lwr, ymax = upr, #confidence interval \n        fill = SEASON), #different fill depending on the SEASON variable \n    stat = 'identity') + #tells geom_smooth to use what is in the dataframe and not calculate anything else\n  \n  scale_colour_manual(values = c(spring=\"green\", summer = \"red\")) + #color for the regression line\n  scale_fill_manual(values = c(spring=\"green\", summer = \"red\")) + #color for the confidence interval area \n  theme_bw()"},{"path":"getting-started-with-generalized-linear-models.html","id":"getting-started-with-generalized-linear-models","chapter":"7 Getting Started with Generalized Linear Models","heading":"7 Getting Started with Generalized Linear Models","text":"Response variables linear model-based analyses several common features including :\nassume continuous variables can take negative positive values can fractions\nalso assume data bounded (practice, sometimes )\nmodels assume normally distributed residuals\nmodel also assumes constant mean-variance relationship\nassume continuous variables can take negative positive values can fractionsWe also assume data bounded (practice, sometimes )models assume normally distributed residualsThe model also assumes constant mean-variance relationshipOften response variables normality assumption violatedExamples data violate assumptions:\nInteger valued data bounded fractioned negative (.e. number people)\nBinary data (.e. presence/absence data)\nInteger valued data bounded fractioned negative (.e. number people)Binary data (.e. presence/absence data)Historically types data, transformations employed log10 transformations counts arcsin(sqrt()) transformations proportion dataThis generalized linear model (GLM) may utilized","code":""},{"path":"getting-started-with-generalized-linear-models.html","id":"counts-and-proportions-and-the-glm","chapter":"7 Getting Started with Generalized Linear Models","heading":"7.0.1 Counts and Proportions and the GLM","text":"Count data:\nbounded 0 infinity\nViolate normality assumption\nconstant mean-variance relationship\nbounded 0 infinityViolate normality assumptionDo constant mean-variance relationshipExample:\nnumber offspring female may produce lifetime relates body size\nrate occurence events (births) depends variables (body size)\n\nnumber offspring female may produce lifetime relates body size\nrate occurence events (births) depends variables (body size)\nrate occurence events (births) depends variables (body size)Proportion data - data often binary\nflowering data\nanimal death\nspecies sex ratios\nflowering dataanimal deathspecies sex ratiosThese occurences often related 1+ explanatory variablesThese data binomial","code":""},{"path":"getting-started-with-generalized-linear-models.html","id":"key-terms-of-glm-models","chapter":"7 Getting Started with Generalized Linear Models","heading":"7.0.2 Key terms of GLM models","text":"Family\nprobability distribution assumed describe response variable\nwords, ’s mathematical statement likely events \nPoisson binomial distributions examples families\nprobability distribution assumed describe response variableIn words, ’s mathematical statement likely events arePoisson binomial distributions examples familiesLinear predictor\nequation describes different predictor variables (explanatory variables) affect expected value response variable\nequation describes different predictor variables (explanatory variables) affect expected value response variableLink function\nDescribes mathematical relationship expected value response variable linear predictor, linking, two aspects GLM\nDescribes mathematical relationship expected value response variable linear predictor, linking, two aspects GLMglm() used create generalized linear models","code":""},{"path":"getting-started-with-generalized-linear-models.html","id":"counts-and-rates---poisson-glms","chapter":"7 Getting Started with Generalized Linear Models","heading":"7.1 Counts and rates - Poisson GLMs","text":"","code":""},{"path":"getting-started-with-generalized-linear-models.html","id":"counting-sheep---the-data-and-question","chapter":"7 Getting Started with Generalized Linear Models","heading":"7.1.1 Counting Sheep - the data and question","text":"dataset, response variable count variableWe aim understand rate occurence events depends 1 explanatory variablesDataset backstory:\n’s specific population sheep\nsheep island west coast Scotland\nunmanaged/feral population Soay sheep\nlot scientific interest population study population evolving\nSeveral studies done female (ewe) fitness\nOne way measure fitness count total number offspring born female life - ‘lifetime reproductive success’\nresponse variable = counts offspring, poorly approximated normal distribution\n\n\n’s specific population sheepThese sheep island west coast ScotlandThey unmanaged/feral population Soay sheepThere lot scientific interest population study population evolvingSeveral studies done female (ewe) fitness\nOne way measure fitness count total number offspring born female life - ‘lifetime reproductive success’\nresponse variable = counts offspring, poorly approximated normal distribution\n\nOne way measure fitness count total number offspring born female life - ‘lifetime reproductive success’\nresponse variable = counts offspring, poorly approximated normal distribution\nresponse variable = counts offspring, poorly approximated normal distributionquestion: lifetime reproductive success increase ewe bodymass?\nlarger ewes produce offspring?\n, heritable difference body mass - selection pressure trait?\nlarger ewes produce offspring?, heritable difference body mass - selection pressure trait?Visualize data:Based loose fitting models, strong positive relationship fitness body size larger ewes offspring time\nLarger ewes resources allocate reproduction\nLarger ewes resources allocate reproductionThe red line clearly captures relationship effectively blue oneThe upward trending red line issue non-linearityThere also subtler issues dataTo really understand problems, authors want analyze data incorrect way right wrongs correct analysis ","code":"\ninstall.packages(\"ggplot2\",  repos = \"https://cran.us.r-project.org\")\ninstall.packages(\"dplyr\",  repos = \"https://cran.us.r-project.org\")\ninstall.packages(\"ggfortify\",  repos = \"https://cran.us.r-project.org\")\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(ggfortify)\nurlfile07a=\"https://raw.githubusercontent.com/apicellap/data/main/SoaySheepFitness.csv\"\nsoay<-read.csv(url(urlfile07a))\nstr(soay)## 'data.frame':    50 obs. of  2 variables:\n##  $ fitness  : int  4 3 2 14 5 2 2 5 8 4 ...\n##  $ body.size: num  6.37 7.18 6.16 8.6 7.33 ...\nggplot(soay, aes(x = body.size, y = fitness)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE) + #applies linear regression (blue) line \n  geom_smooth(span = 1,                    #determines how wiggly the curve is \n              colour = \"red\", se = FALSE) + #applies a non-linear and more  flexible statistical model  \n  xlab(\"Body mass (kg)\") + ylab(\"Lifetime fitness\")## `geom_smooth()` using formula 'y ~ x'## `geom_smooth()` using method = 'loess' and formula 'y ~ x'"},{"path":"getting-started-with-generalized-linear-models.html","id":"doing-it-wrong","chapter":"7 Getting Started with Generalized Linear Models","heading":"7.2 Doing it wrong","text":"Create inappropriate model using linear model approach:Almost assumptions violated","code":"\nsoay.mod <- lm(fitness ~ body.size, data = soay)\nautoplot(soay.mod, smooth.colour = NA) "},{"path":"getting-started-with-generalized-linear-models.html","id":"doing-it-wrong-diagnosing-the-problems","chapter":"7 Getting Started with Generalized Linear Models","heading":"7.2.1 Doing it wrong: diagnosing the problems","text":"Residuals vs fitted values (upper left):\nSuggests systematic part model inappropriate pattern datapoints\nfact, U-shape data indicate straight-line model fails account curvature relationship two variables\n\nFitness underestimated small body sizes\nFitness overestimated larger body sizes\nSuggests systematic part model inappropriate pattern datapoints\nfact, U-shape data indicate straight-line model fails account curvature relationship two variables\nfact, U-shape data indicate straight-line model fails account curvature relationship two variablesFitness underestimated small body sizesFitness overestimated larger body sizesNormal Q-Q plot (upper right):\npoints dashed diagnonal line \nMany points positive territory line\nMany points negative territory line\n\nsee pattern distribution residuals symmetrical\ncase, skewed right\n\npoints dashed diagnonal line \nMany points positive territory line\nMany points negative territory line\nMany points positive territory lineMany points negative territory lineWe see pattern distribution residuals symmetrical\ncase, skewed right\ncase, skewed rightVisualize rightward skew histogram:Scale location plot (bottom left):\nclear pattern shows positive relationship absolute size residuals fitted values\nreflects way fitness values scattered around red line: vertical spread data larger fitness values\nBased , can say positive mean-variance relationship data\nwords, large predicted fitness values associated variation residuals\ntypical count data\n\nclear pattern shows positive relationship absolute size residuals fitted values\nreflects way fitness values scattered around red line: vertical spread data larger fitness values\nBased , can say positive mean-variance relationship data\nwords, large predicted fitness values associated variation residuals\ntypical count data\nreflects way fitness values scattered around red line: vertical spread data larger fitness valuesBased , can say positive mean-variance relationship dataIn words, large predicted fitness values associated variation residualsThis typical count dataResiduals-leverage plot (bottom right):\nplot bad\nextreme standardized residual values\nobvious outliers\n\nNone observations outsized effect model\nplot badThere extreme standardized residual values\nobvious outliers\nobvious outliersNone observations outsized effect modelOverall, normal linear regression good job describing data","code":"\nggplot(soay, aes(x=body.size))+ geom_histogram(bins=20)"},{"path":"getting-started-with-generalized-linear-models.html","id":"the-poisson-distribution---a-solution","chapter":"7 Getting Started with Generalized Linear Models","heading":"7.2.2 The Poisson distribution - a solution","text":"normality assumption built linear regression model appropriate data - Properties normal distribution:\nConcerns continuous variables (can assume fractional values)\nCount data discete (.e. ewe can produce 0,1,2, etc. lambs)\n\nNormal distribution allows negative values\nCount data must positive (.e. ewe -2 offspring)\n\nSymmetry.\nCount data often asymmetrical\n\nConcerns continuous variables (can assume fractional values)\nCount data discete (.e. ewe can produce 0,1,2, etc. lambs)\nCount data discete (.e. ewe can produce 0,1,2, etc. lambs)Normal distribution allows negative values\nCount data must positive (.e. ewe -2 offspring)\nCount data must positive (.e. ewe -2 offspring)Symmetry.\nCount data often asymmetrical\nCount data often asymmetricalPoisson distribution good starting point analysis certain forms count dataThe figure displays three Poisson distributions different meanThe x-axis range different possible values y axis probability valueReasons poisson distribution good model Soay data:\ndiscete counts possible\nData bounded 0\nlarge counts possible scope model; however, occurence unlikely\nVariance distribution increases mean distribution increased\ncorresponds widening base distribution higher mean\n\ndiscete counts possibleData bounded 0Very large counts possible scope model; however, occurence unlikelyVariance distribution increases mean distribution increased\ncorresponds widening base distribution higher mean\ncorresponds widening base distribution higher meanThe poisson distribution best equipped unbounded count data\nunbounded refers just uppper limit values count variable may take\nobvious biological constraints, don’t actually know limit\nunbounded refers just uppper limit values count variable may takeThere obvious biological constraints, don’t actually know limit","code":""},{"path":"getting-started-with-generalized-linear-models.html","id":"doing-it-right---the-poisson-glm","chapter":"7 Getting Started with Generalized Linear Models","heading":"7.3 Doing it right - the Poisson GLM","text":"","code":""},{"path":"getting-started-with-generalized-linear-models.html","id":"anatomy-of-a-glm","chapter":"7 Getting Started with Generalized Linear Models","heading":"7.3.1 Anatomy of a GLM","text":"GLM comprised three key terms: family, linear predictor, link functionGLM comprised three key terms: family, linear predictor, link functionfamily:\nerror aspect GLM\nDetermines kind distribution used describe response variable. Options:\nPoisson distribution\nBinomial distribution\nGamma distribution (positive valued, continuous variables)\nexotic versions\n\noption appropriate specific types data\nfamily:error aspect GLMDetermines kind distribution used describe response variable. Options:\nPoisson distribution\nBinomial distribution\nGamma distribution (positive valued, continuous variables)\nexotic versions\nPoisson distributionBinomial distributionGamma distribution (positive valued, continuous variables)exotic versionsEach option appropriate specific types datalinear predictor:\nEvery time model built lm() function, data R formula must supplied define model\nR formula defines linear predictor\nSoay example:\ninappropriate regression model: lm(fitness ~ body.size, data = soay)\ntells R build model predicted fitness given intercept body size slope term: Predicted fitness = Intercept + Slope x Body size\nlinear predictor ‘Intercept + Slope x Body size’\n’s basically just model\n\nCoefficients shown summary(soay.mod) just intercepts slopes th linear predictor\n\nlinear predictor:Every time model built lm() function, data R formula must supplied define modelThe R formula defines linear predictorSoay example:\ninappropriate regression model: lm(fitness ~ body.size, data = soay)\ntells R build model predicted fitness given intercept body size slope term: Predicted fitness = Intercept + Slope x Body size\nlinear predictor ‘Intercept + Slope x Body size’\n’s basically just model\n\nCoefficients shown summary(soay.mod) just intercepts slopes th linear predictor\ninappropriate regression model: lm(fitness ~ body.size, data = soay)tells R build model predicted fitness given intercept body size slope term: Predicted fitness = Intercept + Slope x Body sizeThe linear predictor ‘Intercept + Slope x Body size’\n’s basically just model\n’s basically just modelCoefficients shown summary(soay.mod) just intercepts slopes th linear predictorThe link function:\nmodel make impossible predictions preferred\ncan plug numbers formul produce illogical outputs :\nnegative number offspring sheep example\n\nGLM, instead trying model predicted values response variable directly, model mathematical transformation prediction\ntransformation link function\n\n\nUsing Poisson GLM model fitness vs body mass relationship, model predicted fitness look like :\nLog[Predicted fitness] = Intercept + Slope x Body size\nnatural log case\nlink function standard Poisson GLM always natural log\n\n\nInstead linear predictor describing fitness directly, relates natural logarithm predicted fitness body size\nmust positive, log transformed value can take value\n\nSolve predicted fitness get:\nPredicted fitness = e^{Intercept + Slope x Body size}\nlink function:model make impossible predictions preferred\ncan plug numbers formul produce illogical outputs :\nnegative number offspring sheep example\n\nGLM, instead trying model predicted values response variable directly, model mathematical transformation prediction\ntransformation link function\n\ncan plug numbers formul produce illogical outputs :\nnegative number offspring sheep example\nnegative number offspring sheep exampleWith GLM, instead trying model predicted values response variable directly, model mathematical transformation prediction\ntransformation link function\ntransformation link functionUsing Poisson GLM model fitness vs body mass relationship, model predicted fitness look like :\nLog[Predicted fitness] = Intercept + Slope x Body size\nnatural log case\nlink function standard Poisson GLM always natural log\n\nLog[Predicted fitness] = Intercept + Slope x Body size\nnatural log case\nlink function standard Poisson GLM always natural log\nnatural log caseThe link function standard Poisson GLM always natural logInstead linear predictor describing fitness directly, relates natural logarithm predicted fitness body size\nmust positive, log transformed value can take value\nmust positive, log transformed value can take valueSolve predicted fitness get:Predicted fitness = e^{Intercept + Slope x Body size}Poisson GLM Soays sheep implies exponential relationship fitness body mass\nlinear model mean linear relationship\nPoisson GLM Soays sheep implies exponential relationship fitness body masslinear model mean linear relationshipThe link function allows estimation paramenteres linear predictor apporpriate data\naccomplished transforming response ‘scale’ scale linear predictor, case natural log scale, defined link function\ncan visualized following figure:\nlink function allows estimation paramenteres linear predictor apporpriate dataThis accomplished transforming response ‘scale’ scale linear predictor, case natural log scale, defined link functionThis can visualized following figure:Figure:\nCount data bounded 0 positive infinity\nPredicted values must greater 0 valid count data\n\n, effective statistics, need operate scale unbounded\nUsing link function accomplishes \nmoves us positive numbers (predicted average counts) scale whole number line (linear predictor) scale\nCount data bounded 0 positive infinity\nPredicted values must greater 0 valid count data\nPredicted values must greater 0 valid count dataBut, effective statistics, need operate scale unboundedUsing link function accomplishes thisIt moves us positive numbers (predicted average counts) scale whole number line (linear predictor) scale","code":""},{"path":"getting-started-with-generalized-linear-models.html","id":"doing-it-right---actually-fitting-the-model","chapter":"7 Getting Started with Generalized Linear Models","heading":"7.3.2 Doing it right - actually fitting the model","text":"Build GLM:","code":"\nsoay.glm <- glm(fitness ~ body.size, data = soay, \n                family = poisson(\n                  link = log)) #this line is unnecessary because the log link function is the default for poisson glm "},{"path":"getting-started-with-generalized-linear-models.html","id":"doing-it-right---the-diagnostics","chapter":"7 Getting Started with Generalized Linear Models","heading":"7.3.3 Doing it right - the diagnostics","text":"Overall, diagnostics look much better\nResiduals vs fitted values (upper left):\nsystematic aspect model fairly appropriate\nclear pattern relationship apart slight upward trend\nenough concerned though\n\n\nNormal Q-Q plot (upper right):\ndeparture dashed diagnonal line, perfect plot expected\nConfirms distributional assumptions okay\n\nScale location plot (bottom left):\nslight positve relationship size residuals fitted values, much concern\n\nResiduals-leverage plot (bottom right):\nShows evidence outliers points outsized effect model\n\nResiduals vs fitted values (upper left):\nsystematic aspect model fairly appropriate\nclear pattern relationship apart slight upward trend\nenough concerned though\n\nsystematic aspect model fairly appropriate\nclear pattern relationship apart slight upward trend\nenough concerned though\nclear pattern relationship apart slight upward trendNot enough concerned thoughNormal Q-Q plot (upper right):\ndeparture dashed diagnonal line, perfect plot expected\nConfirms distributional assumptions okay\ndeparture dashed diagnonal line, perfect plot expectedConfirms distributional assumptions okayScale location plot (bottom left):\nslight positve relationship size residuals fitted values, much concern\nslight positve relationship size residuals fitted values, much concernResiduals-leverage plot (bottom right):\nShows evidence outliers points outsized effect model\nShows evidence outliers points outsized effect modelKeep mind R diagnostics GLM, uses standardized deviance residuals\ntransformed version raw residuals make transformed residuals normally distributed GLM family used appropriate\nmeans chosen family appropriate data, diagnostics show residuals normally distributed\ndiagnostic plots can evaluated way linear model tests jobs\ntransformed version raw residuals make transformed residuals normally distributed GLM family used appropriateThis means chosen family appropriate data, diagnostics show residuals normally distributedAnd diagnostic plots can evaluated way linear model tests jobs","code":"\nautoplot(soay.glm, smooth.colour = NA) "},{"path":"getting-started-with-generalized-linear-models.html","id":"doing-it-right---anova-and-summary","chapter":"7 Getting Started with Generalized Linear Models","heading":"7.3.4 Doing it right - anova() and summary()","text":"Thus far looks fitnesss positively related body massThe next step test hypothesesCreate Analysis Deviance table GLM:“Deviance” closely related idea likelihood, general tool statistics\nShort explanation likelihood: provides us measure probable data really produced model\nUsing likelihood, can find set best-fitting model coefficients picking values maximize likelihood\nAlso, sum squares mean squares allow comparison different models normality assumed\nLikelihood (deviance) thing GLMs\n\nShort explanation likelihood: provides us measure probable data really produced model\nUsing likelihood, can find set best-fitting model coefficients picking values maximize likelihood\nAlso, sum squares mean squares allow comparison different models normality assumed\nLikelihood (deviance) thing GLMs\nUsing likelihood, can find set best-fitting model coefficients picking values maximize likelihoodAlso, sum squares mean squares allow comparison different models normality assumedLikelihood (deviance) thing GLMsno p values table\nTotal deviance NULL (fitness) 85.081 body.size explains 37.041 units deviance - bodysize accounts almost half deviance. large.\np value R wants type test calculate specified\nTotal deviance NULL (fitness) 85.081 body.size explains 37.041 units deviance - bodysize accounts almost half deviance. large.p value R wants type test calculate specifiedp values GLM involve \\(\\chi\\)\\(^{2}\\) distribution rather F-distribution (mean \\(\\chi\\)\\(^{2}\\) test performed)Specifiy type test:test statistic value 37.041\ncorresponding p value small\nunsurprising given strong relationship visualized scatterplot\nlikelihood ratio test\ncorresponding p value smallThis unsurprising given strong relationship visualized scatterplotThis likelihood ratio testThis means fitness vary positively body size selection pressure higher body massFind model:Table output:\nFirst chunk self explanatory\nSecond chunk - “useless” summary specially scaled (deviance) residuals\nThird chunk - coefficients\nmodel line two coefficients - intercept slope\ncoefficient standard error tell us precise z-value help us determine estimate significantly different 0 associated p value\n\nFourth chunk - dispersion parameter - later\nFifth chunk - summaries null deviance, residual deviance, dfs\nnull deviance - measure ‘variation’ data\nresidual deviance - measure left fitting model\nbigger difference two values, variation explained model\n\n\nAIC = Akaike information criterion (analyzed text)\nNumber Fisher Scoring iterations - important\nFirst chunk self explanatorySecond chunk - “useless” summary specially scaled (deviance) residualsThird chunk - coefficients\nmodel line two coefficients - intercept slope\ncoefficient standard error tell us precise z-value help us determine estimate significantly different 0 associated p value\nmodel line two coefficients - intercept slopeEach coefficient standard error tell us precise z-value help us determine estimate significantly different 0 associated p valueFourth chunk - dispersion parameter - laterFifth chunk - summaries null deviance, residual deviance, dfs\nnull deviance - measure ‘variation’ data\nresidual deviance - measure left fitting model\nbigger difference two values, variation explained model\n\nnull deviance - measure ‘variation’ dataresidual deviance - measure left fitting model\nbigger difference two values, variation explained model\nbigger difference two values, variation explained modelAIC = Akaike information criterion (analyzed text)Number Fisher Scoring iterations - importantUpon looking original scatterplot helped visualize data summary table, might confusing see intercept negative value\nremember link function used predict natural logarithm lifetime fitness, actual fitness\nremember link function used predict natural logarithm lifetime fitness, actual fitnessWe revisit overdispersion concept later chapter","code":"\nanova(soay.glm)## Analysis of Deviance Table\n## \n## Model: poisson, link: log\n## \n## Response: fitness\n## \n## Terms added sequentially (first to last)\n## \n## \n##           Df Deviance Resid. Df Resid. Dev\n## NULL                         49     85.081\n## body.size  1   37.041        48     48.040\nanova(soay.glm, test = \"Chisq\")## Analysis of Deviance Table\n## \n## Model: poisson, link: log\n## \n## Response: fitness\n## \n## Terms added sequentially (first to last)\n## \n## \n##           Df Deviance Resid. Df Resid. Dev  Pr(>Chi)    \n## NULL                         49     85.081              \n## body.size  1   37.041        48     48.040 1.157e-09 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nsummary(soay.glm)## \n## Call:\n## glm(formula = fitness ~ body.size, family = poisson(link = log), \n##     data = soay)\n## \n## Deviance Residuals: \n##     Min       1Q   Median       3Q      Max  \n## -2.7634  -0.6275   0.1142   0.5370   1.9578  \n## \n## Coefficients:\n##             Estimate Std. Error z value Pr(>|z|)    \n## (Intercept) -2.42203    0.69432  -3.488 0.000486 ***\n## body.size    0.54087    0.09316   5.806 6.41e-09 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for poisson family taken to be 1)\n## \n##     Null deviance: 85.081  on 49  degrees of freedom\n## Residual deviance: 48.040  on 48  degrees of freedom\n## AIC: 210.85\n## \n## Number of Fisher Scoring iterations: 4"},{"path":"getting-started-with-generalized-linear-models.html","id":"making-a-beautiful-graph","chapter":"7 Getting Started with Generalized Linear Models","heading":"7.3.5 Making a beautiful graph","text":"Need generate set new x valuesGenerate new x values:Now predict() function can used:\npredict() given three arguments: GLM model, value newdata, request standard errors\nSide note: predict() glm confidence interval argument, manually rendered dataframe\npredict() given three arguments: GLM model, value newdata, request standard errorsSide note: predict() glm confidence interval argument, manually rendered dataframeCombine new x values new y values:Calculate include confidence intervals dataframe:Visualize data new model + predicted values:didn’t work:happened default scale predict() just scale link functionThe link function uses logarithmic scale\nmeans predictions log expected fitness, want plot actual fitness values\nmeans predictions log expected fitness, want plot actual fitness valuesTo fix , inverse log must applied y-axis variables addThese\ninverse log, just exponentiate \ninverse log, just exponentiate themRecreate y values:Exponentiate y values:Revisulize data:","code":"\nmin.size = min(soay$body.size)\nmax.size = max(soay$body.size)\n\nnew.x = expand.grid(body.size = \n                      seq(min.size, max.size, #the new x values will be between these two parameters \n                          length = 1000)) #R generates 1000 values between \nnew.y <- predict(soay.glm, \n                 newdata = new.x, #instructs R to use the new x values \n                 se.fit = TRUE) #provides standard errors.predict() for glm() doesn't have an interval = confidence argument\nnew.y = data.frame(new.y) #converts new.y into a dataframe \nhead(new.y)##         fit    se.fit residual.scale\n## 1 0.1661991 0.2541777              1\n## 2 0.1682619 0.2538348              1\n## 3 0.1703247 0.2534919              1\n## 4 0.1723874 0.2531491              1\n## 5 0.1744502 0.2528063              1\n## 6 0.1765130 0.2524635              1\naddThese = data.frame(new.x, new.y)\nnames(addThese)[names(addThese) == 'fit'] <- 'fitness' #this will match the original data \n\nhead(addThese)##   body.size   fitness    se.fit residual.scale\n## 1  4.785300 0.1661991 0.2541777              1\n## 2  4.789114 0.1682619 0.2538348              1\n## 3  4.792928 0.1703247 0.2534919              1\n## 4  4.796741 0.1723874 0.2531491              1\n## 5  4.800555 0.1744502 0.2528063              1\n## 6  4.804369 0.1765130 0.2524635              1\naddThese = mutate(addThese, \n                  lwr = fitness -1.96 * se.fit, #this and the line below add the lower and upper bounds of the 95% CI \n                  upr = fitness +1.96 * se.fit)\nhead(addThese)##   body.size   fitness    se.fit residual.scale        lwr       upr\n## 1  4.785300 0.1661991 0.2541777              1 -0.3319891 0.6643874\n## 2  4.789114 0.1682619 0.2538348              1 -0.3292543 0.6657781\n## 3  4.792928 0.1703247 0.2534919              1 -0.3265195 0.6671689\n## 4  4.796741 0.1723874 0.2531491              1 -0.3237848 0.6685597\n## 5  4.800555 0.1744502 0.2528063              1 -0.3210501 0.6699506\n## 6  4.804369 0.1765130 0.2524635              1 -0.3183156 0.6713415\nggplot(soay, aes(x = body.size, y = fitness)) + \n  geom_point(size = 3, alpha = 0.5) + \n  geom_smooth(data = addThese, \n              aes(ymin = lwr, ymax = upr), stat = 'identity') + \n  theme_bw()\nmin.size = min(soay$body.size)\nmax.size = max(soay$body.size)\n\nnew.x = expand.grid(body.size = seq(min.size, max.size, length = 1000)) \n\nnew.y <- predict(soay.glm, \n                 newdata = new.x, \n                 se.fit = TRUE)  \nnew.y = data.frame(new.y) \naddThese = data.frame(new.x, new.y)\nhead(addThese)##   body.size       fit    se.fit residual.scale\n## 1  4.785300 0.1661991 0.2541777              1\n## 2  4.789114 0.1682619 0.2538348              1\n## 3  4.792928 0.1703247 0.2534919              1\n## 4  4.796741 0.1723874 0.2531491              1\n## 5  4.800555 0.1744502 0.2528063              1\n## 6  4.804369 0.1765130 0.2524635              1\naddThese = mutate(addThese, \n                  fitness = exp(fit),\n                  lwr = exp(fit - 1.96 *se.fit), \n                  upr = exp(fit - 1.96*se.fit)) \nhead(addThese)##   body.size       fit    se.fit residual.scale  fitness       lwr       upr\n## 1  4.785300 0.1661991 0.2541777              1 1.180808 0.7174951 0.7174951\n## 2  4.789114 0.1682619 0.2538348              1 1.183246 0.7194600 0.7194600\n## 3  4.792928 0.1703247 0.2534919              1 1.185690 0.7214303 0.7214303\n## 4  4.796741 0.1723874 0.2531491              1 1.188138 0.7234059 0.7234059\n## 5  4.800555 0.1744502 0.2528063              1 1.190591 0.7253869 0.7253869\n## 6  4.804369 0.1765130 0.2524635              1 1.193050 0.7273732 0.7273732\nggplot(soay, aes(x = body.size, y = fitness)) + \n  geom_point(size = 3, alpha = 0.5) + \n  geom_smooth(data = addThese, \n              aes(ymin = lwr, ymax = upr), stat = 'identity') + \n  theme_bw()"},{"path":"getting-started-with-generalized-linear-models.html","id":"when-a-poisson-glm-isnt-good-for-counts","chapter":"7 Getting Started with Generalized Linear Models","heading":"7.4 When a Poisson GLM isn’t good for counts","text":"previous data set best case scenario GLM simplest use caseNow work realistic data","code":""},{"path":"getting-started-with-generalized-linear-models.html","id":"overdispersion","chapter":"7 Getting Started with Generalized Linear Models","heading":"7.4.1 Overdispersion","text":"Overdispersion means ‘extra variation’GLMs make strong assumptions nature variability data\nseen variance increases mean\nPoisson distribution, variance equal mean\nassumption can true can account every source variation data (big assumption esp biology)\n\nBiology creates variation measured accounted \nsource overdisperson problem\nnon-independence data\nNon-independence refers idea elements data similiar one another things\n.e. cannabis plants experiment similiar random plant\n\n\nseen variance increases meanFor Poisson distribution, variance equal mean\nassumption can true can account every source variation data (big assumption esp biology)\nassumption can true can account every source variation data (big assumption esp biology)Biology creates variation measured accounted forThis source overdisperson problem\nnon-independence data\nNon-independence refers idea elements data similiar one another things\n.e. cannabis plants experiment similiar random plant\n\nnon-independence data\nNon-independence refers idea elements data similiar one another things\n.e. cannabis plants experiment similiar random plant\nNon-independence refers idea elements data similiar one another thingsi.e. cannabis plants experiment similiar random plantoverdispersion sounds like BS can really mess statistical output ignored (.e. p-values) end false positivesWhat ?\nFirst: detect .\nFirst: detect .GLM working appropriately overdispersion, residual deviance (48.040) degrees freedom (48) equalPerform \\(\\frac{residual~deviance}{residual~degrees~~freedom}\\)output ‘dispersion index (DI)’ approximately 1\nmuch bigger 1, data overdispersed\nrule thumb, \\(DI \\ge 2\\)\n\nmuch less 1, data underdispersed (rare)\nmuch bigger 1, data overdispersed\nrule thumb, \\(DI \\ge 2\\)\nrule thumb, \\(DI \\ge 2\\)much less 1, data underdispersed (rare)Fortunately, soay data normal dispersion levelsIf data overdispersed, can model data differentlyA simple fix change family glm() family = poisson family = quasipoisson\nquasi model works just like glm also estimates dispersion index much clever way \nindex value known, R can adjust p-values accordingly\nquasi model works just like glm also estimates dispersion index much clever way didOnce index value known, R can adjust p-values accordinglyCan also switch negative binomial family\nnegative binomial distribution thought flexible Poisson distribution\nvariance increases mean, less constrained way. variance equal mean\nnegative binomial distribution thought flexible Poisson distributionThe variance increases mean, less constrained way. variance equal meanThe difference summary statistics table original one soay glm p-values. based method accounts /underdispersionOne thing. Need tell R take account estimated dispersion :","code":"\nsummary(soay.glm)## \n## Call:\n## glm(formula = fitness ~ body.size, family = poisson(link = log), \n##     data = soay)\n## \n## Deviance Residuals: \n##     Min       1Q   Median       3Q      Max  \n## -2.7634  -0.6275   0.1142   0.5370   1.9578  \n## \n## Coefficients:\n##             Estimate Std. Error z value Pr(>|z|)    \n## (Intercept) -2.42203    0.69432  -3.488 0.000486 ***\n## body.size    0.54087    0.09316   5.806 6.41e-09 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for poisson family taken to be 1)\n## \n##     Null deviance: 85.081  on 49  degrees of freedom\n## Residual deviance: 48.040  on 48  degrees of freedom\n## AIC: 210.85\n## \n## Number of Fisher Scoring iterations: 4\nsoay.glm2 <- glm(fitness ~ body.size, data = soay, \n                family = quasipoisson(\n                  link = log)) \nsummary(soay.glm2)## \n## Call:\n## glm(formula = fitness ~ body.size, family = quasipoisson(link = log), \n##     data = soay)\n## \n## Deviance Residuals: \n##     Min       1Q   Median       3Q      Max  \n## -2.7634  -0.6275   0.1142   0.5370   1.9578  \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept) -2.42203    0.65967  -3.672 0.000605 ***\n## body.size    0.54087    0.08851   6.111  1.7e-07 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for quasipoisson family taken to be 0.9026887)\n## \n##     Null deviance: 85.081  on 49  degrees of freedom\n## Residual deviance: 48.040  on 48  degrees of freedom\n## AIC: NA\n## \n## Number of Fisher Scoring iterations: 4\nanova(soay.glm, \n      test = \"F\") #instead of Chisq## Analysis of Deviance Table\n## \n## Model: poisson, link: log\n## \n## Response: fitness\n## \n## Terms added sequentially (first to last)\n## \n## \n##           Df Deviance Resid. Df Resid. Dev     F    Pr(>F)    \n## NULL                         49     85.081                    \n## body.size  1   37.041        48     48.040 37.04 1.157e-09 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"getting-started-with-generalized-linear-models.html","id":"negative-binomials","chapter":"7 Getting Started with Generalized Linear Models","heading":"7.4.1.1 Negative binomials","text":"Use glm.nb() build negative binomial models MASS package (base-R)little else new need learnThe default link function natural log, can check ?glm.nb alternativesNeither quasi negative binomial models appropriately deal overdispersion caused non-independence\njob mixed models, discussed text\njob mixed models, discussed text","code":""},{"path":"getting-started-with-generalized-linear-models.html","id":"zero-inflation","chapter":"7 Getting Started with Generalized Linear Models","heading":"7.4.2 Zero inflation","text":"One specific source overdispersion Poisson-like count data known zero-inflationThis occurs many zeroes relative expected number whichever distribution used\ncount zero-inflated, can often spot chart raw counts (.e. spike 0 bar chart - often results zero-inflation)\ncount zero-inflated, can often spot chart raw counts (.e. spike 0 bar chart - often results zero-inflation)Biological counts often zero-inflated\nOccurs binary results combine Poisson process\nOccurs binary results combine Poisson process","code":""},{"path":"getting-started-with-generalized-linear-models.html","id":"transformations-aint-all-bad","chapter":"7 Getting Started with Generalized Linear Models","heading":"7.4.3 Transformations ain’t all bad","text":"Sometimes transformations appropriate, sometimes notWhen doubt, build model test diagnosticsIf diagnostics look okay, ’s probably fine use modelAdvantages using transformations:\nwork well data far away zero (zeroes), don’t span orders magnitiude\nCan analyze “split-plot” designs fairly easily\nwork well data far away zero (zeroes), don’t span orders magnitiudeCan analyze “split-plot” designs fairly easily","code":""},{"path":"chapter-8-pimping-your-plots.html","id":"chapter-8-pimping-your-plots","chapter":"8 Chapter 8: Pimping Your Plots","heading":"8 Chapter 8: Pimping Your Plots","text":"Create base scatterplot:Create base boxplot:Render blank background:Arrange plots gridExtra:Change axes’ bounds:Add text plot:Modify axis scales:Transform scale:Modifying theme:Modify elements x axis:Modify axis labels (categorical variables):Modify legend:","code":"\ninstall.packages(\"ggplot2\",  repos = \"https://cran.us.r-project.org\")\ninstall.packages(\"dplyr\",  repos = \"https://cran.us.r-project.org\")\ninstall.packages(\"gridExtra\",  repos = \"https://cran.us.r-project.org\")\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(gridExtra)\nurlfile08a=\"https://raw.githubusercontent.com/apicellap/data/main/compensation.csv\"\ncompensation<-read.csv(url(urlfile08a))\nhead(compensation)##    Root Fruit  Grazing\n## 1 6.225 59.77 Ungrazed\n## 2 6.487 60.98 Ungrazed\n## 3 4.919 14.73 Ungrazed\n## 4 5.130 19.28 Ungrazed\n## 5 5.417 34.25 Ungrazed\n## 6 5.359 35.53 Ungrazed\neg_scatter <- ggplot(compensation, aes(x = Root, y = Fruit)) +\n                     geom_point()\neg_scatter\neg_box <- ggplot(compensation, aes(x = Grazing, y = Fruit)) +\n  geom_boxplot() \neg_box\neg_scatter + theme_bw()\ngrid.arrange(          \n  eg_scatter, eg_box,\n  nrow =1) #specifies the arrangement \neg_scatter +  xlim(0,20) +ylim(0,140) \neg_scatter + annotate(\"text\", \n                      x=c(6,8), #6 and 105 are the x,y coordinates for placing the label\n                      y=c(105,25),\n                      label = c(\"here\",\"there\"))\neg_scatter + \n  scale_x_continuous(limits = c(4,11), #bounds \n                     breaks = 4:11)  #tick marks at 1 step between the bounds \nggplot(compensation, aes(x = Root, y = Fruit, \n                         color = Grazing)) + #need to add the color to aes for scale_color_manual() to function  \n  geom_point() + \n  scale_color_manual(values = c(Grazed = \"brown\", Ungrazed = \"green\"))\neg_box + scale_y_continuous(breaks = seq(from = 10, to = 150,\n                                         by = 20), #vector breakpoints that call for ticks \n                            trans = \"log10\") #log transformation of y axis\neg_scatter + \n  theme(\n    panel.background = element_rect(fill = NA, colour = \"black\"), #backgrounds is white \n    panel.grid.minor = element_blank(), #no minor gridlines \n    panel.grid.major = element_line(colour = \"lightblue\") #gridlines are blue \n  )\neg_box + \n  theme(\n    axis.title.x = element_text(color = \"cornflowerblue\",\n    size = rel(2)), #relative increase above the default setting \n    axis.text.x = element_text(angle = 45, #angle of x axis labels \n                               size = 13, \n                               vjust =0.5 ) #scoots labels down a bit; can accept values from 0-1\n  )\neg_box + \n    scale_x_discrete(limits = c(\"Ungrazed\", \"Grazed\"), #limits refer to variables in the dataframe\n                     labels = c(\"Control\", \"Grazed\")) #labels() corresponds to the limits and lets you change them without altering the df\nggplot(compensation, aes(x = Root, y = Fruit, color = Grazing)) + \n  geom_point() + \n  theme(legend.key = element_rect(fill = NA)) #removes box around the legend "}]
